#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŸºäºäººç±»é€»è¾‘çš„é¢˜ç›®æå–å™¨æœåŠ¡
å®ç°ç®€å•ã€é«˜æ•ˆã€å‡†ç¡®çš„é¢˜ç›®æå–é€»è¾‘
"""

from docx import Document
from docx.oxml.ns import nsmap
import re
import os
import uuid
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
import io
import logging

logger = logging.getLogger(__name__)


class HumanLogicQuestionExtractor:
    """åŸºäºäººç±»é€»è¾‘çš„é¢˜ç›®æå–å™¨"""
    
    def __init__(self):
        self.section_pattern = r'^[ä¸€äºŒä¸‰å››äº”å…­]ã€'
        self.question_pattern = r'^\d+$'
        
    def extract_questions(self, docx_path: str) -> Dict[str, Any]:
        """ä¸»æå–å‡½æ•°"""
        try:
            doc = Document(docx_path)
            logger.info(f"å¼€å§‹æå–é¢˜ç›®ï¼Œæ–‡æ¡£è·¯å¾„: {docx_path}")
            
            # ç¬¬1æ­¥ï¼šæ‰¾åˆ°æ‰€æœ‰é¢˜å‹åˆ†ç•Œç‚¹
            sections = self.find_sections(doc)
            logger.info(f"æ‰¾åˆ° {len(sections)} ä¸ªé¢˜å‹")
            
            # ç¬¬2æ­¥ï¼šåœ¨æ¯ä¸ªé¢˜å‹å†…æ‰¾é¢˜ç›®
            total_questions = 0
            total_images = 0
            
            for section in sections:
                section['questions'] = self.find_questions_in_section(doc, section)
                logger.info(f"{section['name']}: {len(section['questions'])}é“é¢˜")
                total_questions += len(section['questions'])
            
            # ç¬¬3æ­¥ï¼šæå–æ¯é“é¢˜çš„å®Œæ•´å†…å®¹ï¼ˆæŒ‰æ•°æ®é›†åˆ†ç»„åˆå¹¶ææ–™ï¼‰
            all_questions = []
            for section in sections:
                section_questions = section['questions']

                # è®¡ç®—æ¯ä¸ªç»„ï¼ˆï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰ï¼ˆä¸‰ï¼‰â€¦ï¼‰çš„ææ–™å‰è¨€ï¼Œä»…åœ¨ç»„å†…å…±äº«
                preface_by_group = {}
                first_num_idx_by_group = {}
                if section_questions:
                    from collections import defaultdict
                    grouped = defaultdict(list)
                    for q in section_questions:
                        gid = q.get('group_id', 0)
                        grouped[gid].append(q)
                    for gid, qs in grouped.items():
                        first_q = min(qs, key=lambda x: x.get('number_index', x['start']))
                        number_index = first_q.get('number_index', first_q['start'])
                        if first_q['start'] < number_index:
                            preface_by_group[gid] = self.extract_question_content(doc, {
                                'start': first_q['start'],
                                'end': number_index
                            })
                        first_num_idx_by_group[gid] = number_index

                for question in section_questions:
                    raw_content = self.extract_question_content(doc, question)
                    content = raw_content
                    gid = question.get('group_id', 0)
                    first_idx = first_num_idx_by_group.get(gid)
                    is_first_in_group = (first_idx is not None and question.get('number_index') == first_idx)
                    # éæœ¬ç»„é¦–é¢˜éœ€è¦å åŠ æœ¬ç»„ææ–™
                    if gid in preface_by_group and not is_first_in_group:
                        pf = preface_by_group[gid]
                        content = {
                            'paragraphs': list(pf['paragraphs']) + raw_content['paragraphs'],
                            'paragraph_count': pf['paragraph_count'] + raw_content['paragraph_count'],
                            'total_images': pf['total_images'] + raw_content['total_images'],
                            'total_text_length': pf['total_text_length'] + raw_content['total_text_length'],
                        }
                    question_data = {
                        'number': question['number'],
                        'section': section['name'],
                        'number_index': question.get('number_index'),
                        'group_id': question.get('group_id'),
                        'content': content,
                        'paragraph_range': f"{question['start']}-{question['end']}"
                    }
                    all_questions.append(question_data)
                    # æ³¨æ„ï¼šæ­¤å¤„ç´¯è®¡çš„æ˜¯åŸå§‹é¢˜ç›®å›¾ç‰‡æ•°ï¼Œç”¨äºæ•´ä½“æ ¡éªŒï¼›ä¸é‡å¤ç´¯è®¡ç»„å‰è¨€
                    total_images += raw_content.get('total_images', 0)
            
            # éªŒè¯ç»“æœ
            validation = self.validate_extraction_results(all_questions, total_questions, total_images)
            
            return {
                'success': True,
                'total_questions': total_questions,
                'total_images': total_images,
                'sections': {s['name'][:2]: {
                    'name': s['name'],
                    'count': len(s['questions']),
                    'questions': [q['number'] for q in s['questions']],
                    'total_images': sum(self.extract_question_content(doc, q).get('total_images', 0) for q in s['questions'])
                } for s in sections},
                'questions': all_questions,
                'validation': validation
            }
            
        except Exception as e:
            logger.error(f"é¢˜ç›®æå–å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'total_questions': 0,
                'total_images': 0,
                'sections': {},
                'questions': [],
                'validation': {'issues': [f'æå–è¿‡ç¨‹é”™è¯¯: {str(e)}']}
            }
    
    def find_sections(self, doc: Document) -> List[Dict[str, Any]]:
        """æ‰¾é¢˜å‹è¾¹ç•Œ"""
        sections = []
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if re.match(self.section_pattern, text):
                sections.append({
                    'name': text,
                    'start_para': i
                })
        
        # ç¡®å®šæ¯ä¸ªé¢˜å‹çš„ç»“æŸä½ç½®
        for i in range(len(sections)):
            if i + 1 < len(sections):
                sections[i]['end_para'] = sections[i + 1]['start_para']
            else:
                sections[i]['end_para'] = len(doc.paragraphs)
        
        return sections
    
    def find_questions_in_section(self, doc: Document, section: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æå–ç« èŠ‚å†…éƒ¨çš„é¢˜ç›®ç¼–å·èŒƒå›´"""
        questions: List[Dict[str, Any]] = []
        current_start = section['start_para']
        last_boundary = section['start_para']
        dataset_heading_pattern = re.compile(r'^ï¼ˆ[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ï¼‰$')
        in_preface = False
        # åˆ†ç»„IDï¼šé‡åˆ°ï¼ˆï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰ï¼ˆä¸‰ï¼‰â€¦ï¼‰æ—¶é€’å¢ï¼Œç”¨äºèµ„æ–™åˆ†æç­‰å¤§é¢˜åˆ†ç»„
        group_id = 0
        current_group_start = section['start_para']

        for i in range(section['start_para'], section['end_para']):
            if i >= len(doc.paragraphs):
                break
            text = doc.paragraphs[i].text.strip()

            if dataset_heading_pattern.match(text):
                if questions:
                    questions[-1]['end'] = last_boundary
                current_start = i
                last_boundary = i
                in_preface = True
                # æ–°çš„æ•°æ®é›†å¼€å§‹ï¼Œåˆ‡æ¢åˆ°æ–°çš„ç»„
                group_id += 1
                current_group_start = i
                continue

            if re.match(self.question_pattern, text):
                if questions:
                    # ç»“æŸä¸Šä¸€é¢˜åˆ°å½“å‰æ•°å­—æ ‡é¢˜å‰çš„æœ€åä¸€è¡Œ
                    questions[-1]['end'] = last_boundary
                # æ–°é¢˜èµ·ç‚¹ä»ä¸Šä¸€æ®µè½è¾¹ç•Œå¼€å§‹ï¼Œç¡®ä¿åŒ…å«æœ¬é¢˜é¢˜å¹²ææ–™ï¼ˆä½äºé¢˜å·å‰çš„å›¾æ–‡ï¼‰
                question_start = current_start if not questions else last_boundary
                questions.append({
                    'number': int(text),
                    'start': question_start,
                    'number_index': i,
                    'group_id': group_id,
                    'group_start': current_group_start
                })
                current_start = i
                last_boundary = i
                in_preface = False
            else:
                if not in_preface:
                    last_boundary = i + 1

        if questions:
            questions[-1]['end'] = max(last_boundary, questions[-1]['number_index'] + 1)

        return questions

    def extract_question_content(self, doc: Document, question: Dict[str, Any]) -> Dict[str, Any]:
        """æå–é¢˜ç›®çš„å®Œæ•´å†…å®¹"""
        content = []
        total_images = 0
        total_text_length = 0
        # é€‰é¡¹è¯†åˆ«ï¼šA/B/C/D + æ ‡ç‚¹ï¼ˆå…¨è§’/åŠè§’ï¼‰
        option_pattern = re.compile(r'^[A-Dï¼¡-ï¼¤][\s\t]*[ã€\.ï¼\)]')
        
        for para_idx in range(question['start'], question['end']):
            if para_idx < len(doc.paragraphs):
                para = doc.paragraphs[para_idx]
                para_text = para.text.strip()
                
                # ç»Ÿè®¡å›¾ç‰‡ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰
                para_images = 0
                for run in para.runs:
                    if hasattr(run._element, 'xml'):
                        xml_str = str(run._element.xml)
                        if '<w:drawing' in xml_str or '<pic:pic' in xml_str or '<v:imagedata' in xml_str:
                            para_images += 1
                
                # é€‰é¡¹æ®µè½çš„å›¾ç‰‡ä¸è®¡å…¥é¢˜ç›®ææ–™å›¾ç‰‡æ€»æ•°
                if not option_pattern.match(para_text):
                    total_images += para_images
                total_text_length += len(para_text)
                
                if para_text or para_images > 0:
                    content.append({
                        'paragraph_index': para_idx,
                        'text': para_text,
                        'images_count': para_images,
                        'text_length': len(para_text)
                    })
        
        return {
            'paragraphs': content,
            'paragraph_count': len(content),
            'total_images': total_images,
            'total_text_length': total_text_length
        }
    
    def validate_extraction_results(self, questions: List[Dict], total_questions: int, total_images: int) -> Dict[str, Any]:
        """éªŒè¯æå–ç»“æœ"""
        issues = []
        
        # éªŒè¯é¢˜ç›®æ•°é‡
        if total_questions != 135:
            issues.append(f"é¢˜ç›®æ•°é‡å¼‚å¸¸: é¢„æœŸ135é“ï¼Œå®é™…{total_questions}é“")
        
        # éªŒè¯é¢˜ç›®ç¼–å·è¿ç»­æ€§
        numbers = [q['number'] for q in questions]
        numbers.sort()
        for i in range(1, len(numbers)):
            if numbers[i] != numbers[i-1] + 1:
                issues.append(f"é¢˜ç›®ç¼–å·ä¸è¿ç»­: {numbers[i-1]} -> {numbers[i]}")
                break
        
        # éªŒè¯å›¾ç‰‡æ•°é‡
        if total_images < 3000:
            issues.append(f"å›¾ç‰‡æ•°é‡åå°‘: é¢„æœŸ3000+å¼ ï¼Œå®é™…{total_images}å¼ ")
        
        return {
            'total_questions': total_questions,
            'total_images': total_images,
            'issues': issues,
            'success_rate': max(0, (135 - len(issues)) / 135 * 100)
        }


class QuestionImageExtractor:
    """é¢˜ç›®å›¾ç‰‡æå–å™¨"""

    def __init__(self, output_dir: str = "images") -> None:
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def extract_images_from_question(self, doc: Document, question_data: Dict[str, Any], question_id: str) -> List[Dict[str, Any]]:
        """ä»é¢˜ç›®å†…å®¹ä¸­æå–å›¾ç‰‡å¹¶ä¿å­˜åˆ°è¾“å‡ºç›®å½•"""
        images: List[Dict[str, Any]] = []
        question_number = question_data.get('number', 0)

        paragraph_range = question_data.get('paragraph_range', '0-0')
        content_paras = question_data.get('content', {}).get('paragraphs', [])
        paragraph_indices = sorted({int(p.get('paragraph_index')) for p in content_paras if p.get('paragraph_index') is not None})

        if not paragraph_indices:
            try:
                start_para, end_para = map(int, paragraph_range.split('-'))
            except ValueError:
                start_para, end_para = 0, len(doc.paragraphs)
            paragraph_indices = list(range(start_para, min(end_para, len(doc.paragraphs))))

        image_index = 0
        # é€‰é¡¹è¯†åˆ«ï¼šA/B/C/D + æ ‡ç‚¹ï¼ˆåŒ…å«å…¨è§’/åŠè§’ï¼‰ã€‚ä»…å½“å‰é¢å‡ºç°è¿‡é¢˜å·åæ‰ç”Ÿæ•ˆ
        option_pattern = re.compile(r'^[A-Dï¼¡-ï¼¤][\s\t]*[ã€\.ï¼\)]')
        seen_question_number = False

        for para_idx in paragraph_indices:
            if not (0 <= para_idx < len(doc.paragraphs)):
                continue
            para = doc.paragraphs[para_idx]
            para_text = para.text.strip()
            # åœ¨é‡åˆ°é¢˜å·æ‰€åœ¨æ®µä¹‹åï¼Œå†è¯†åˆ«é€‰é¡¹æ®µè½ï¼›é¿å…æŠŠææ–™ä¸­å¸¦A/B/Cæ ‡æ³¨è¯¯åˆ¤ä¸ºé€‰é¡¹
            if not seen_question_number:
                number_idx = question_data.get('number_index')
                if number_idx is not None:
                    if para_idx == number_idx:
                        seen_question_number = True
                else:
                    # è‹¥ç¼ºå°‘é¢˜å·ç´¢å¼•åˆ™é»˜è®¤é¦–æ®µä¹‹åå‡è§†ä¸ºé€‰é¡¹
                    seen_question_number = True
            is_option_para = bool(option_pattern.match(para_text)) and seen_question_number

            # å…ˆä» run ä¸­æå–
            seen_hashes: set = set()
            def _emit(img_bytes: bytes, ext: str):
                nonlocal image_index
                # å»é‡ï¼šæŒ‰å‰16å­—èŠ‚åšç®€å•å“ˆå¸Œ
                h = img_bytes[:16]
                if h in seen_hashes:
                    return
                seen_hashes.add(h)
                file_extension = ext if ext else '.png'
                if not file_extension.startswith('.'):
                    file_extension = f'.{file_extension}'
                filename = f"question_{question_number}_{image_index}_{uuid.uuid4().hex[:8]}{file_extension}"
                filepath = os.path.join(self.output_dir, filename)
                if self.save_image_data(img_bytes, filepath):
                    images.append({
                        'filename': filename,
                        'context_text': para_text[:100],
                        'paragraph_index': para_idx,
                        'position_in_question': image_index,
                        'image_type': 'option' if is_option_para else 'material'
                    })
                    image_index += 1

            for run in para.runs:
                image_payload = self.extract_image_from_run(run, doc)
                if image_payload:
                    _emit(image_payload[0], image_payload[1])

            # å…œåº•ï¼šç›´æ¥æ‰«ææ®µè½XMLï¼Œæå– r:embed / r:id å¹¶ä»æ–‡æ¡£å…³ç³»å–å›¾
            try:
                import re as _re
                para_xml = str(getattr(para._element, 'xml', ''))
                rel_ids = _re.findall(r'(?:r:embed|r:id)="([^"]+)"', para_xml)
                for rel_id in rel_ids:
                    part = None
                    try:
                        part = doc.part.related_parts.get(rel_id)
                    except Exception:
                        part = None
                    if part is None:
                        continue
                    img_bytes = getattr(part, 'blob', None) or getattr(part, '_blob', None)
                    if not img_bytes:
                        continue
                    partname = str(getattr(part, 'partname', ''))
                    ext = os.path.splitext(partname)[1].lower()
                    if not ext:
                        content_type = getattr(part, 'content_type', '')
                        ext = self._extension_from_content_type(content_type)
                    _emit(img_bytes, ext)
            except Exception:
                pass

        return images

    def extract_image_from_run(self, run, doc: Document) -> Optional[Tuple[bytes, str]]:
        """ä» run å…ƒç´ è·å–å›¾ç‰‡çš„åŸå§‹æ•°æ®å’Œæ‰©å±•å"""
        try:
            element = run._element

            # ä¼˜å…ˆä½¿ç”¨å‘½åç©ºé—´æ–¹å¼è¯»å–å…³ç³»ID
            ns = {
                'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',
                'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships',
                'v': 'urn:schemas-microsoft-com:vml',
                'o': 'urn:schemas-microsoft-com:office:office',
                'wp': 'http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing',
                'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
                'pic': 'http://schemas.openxmlformats.org/drawingml/2006/picture',
            }
            embed_ids = []
            try:
                embed_ids = element.xpath('.//a:blip/@r:embed', namespaces=ns)
            except Exception:
                embed_ids = []
            if not embed_ids:
                try:
                    embed_ids = element.xpath('.//v:imagedata/@r:id', namespaces=ns)
                except Exception:
                    embed_ids = []
            # å…œåº•ï¼šä½¿ç”¨ local-name() åŒ¹é…ï¼Œé˜²æ­¢å‘½åç©ºé—´ä¸ä¸€è‡´
            if not embed_ids:
                embed_ids = element.xpath(".//*[local-name()='blip']/@*[local-name()='embed']")
            if not embed_ids:
                embed_ids = element.xpath(".//*[local-name()='imagedata']/@*[local-name()='id']")
            # ç»ˆæå…œåº•ï¼šç›´æ¥åœ¨XMLå­—ç¬¦ä¸²é‡Œç”¨æ­£åˆ™æ‰¾ r:embed / r:id
            if not embed_ids:
                try:
                    import re as _re
                    xml_str = str(getattr(element, 'xml', ''))
                    m = _re.findall(r'(?:r:embed|r:id)="([^"]+)"', xml_str)
                    if m:
                        embed_ids = m
                except Exception:
                    pass
            if not embed_ids:
                return None

            rel_id = embed_ids[0]
            image_part = None
            # ä¼˜å…ˆä»å½“å‰ run æ‰€å± part è·å–
            try:
                image_part = run.part.related_parts.get(rel_id)
            except Exception:
                image_part = None
            # å…œåº•ï¼šä»æ•´ä¸ªæ–‡æ¡£ part å…³ç³»é‡Œæ‰¾
            if image_part is None:
                try:
                    image_part = doc.part.related_parts.get(rel_id)
                except Exception:
                    image_part = None
            if image_part is None:
                return None

            # å…¼å®¹ä¸åŒå®ç°çš„å±æ€§å
            image_bytes = getattr(image_part, 'blob', None)
            if image_bytes is None:
                image_bytes = getattr(image_part, '_blob', None)
            if image_bytes is None:
                return None
            partname = str(getattr(image_part, 'partname', ''))
            extension = os.path.splitext(partname)[1].lower()
            if not extension:
                content_type = getattr(image_part, 'content_type', '')
                extension = self._extension_from_content_type(content_type)

            return image_bytes, extension
        except Exception as exc:
            logger.warning(f"æå–å›¾ç‰‡å¤±è´¥: {exc}")
            return None

    @staticmethod
    def _extension_from_content_type(content_type: str) -> str:
        mapping = {
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/bmp': '.bmp',
            'image/tiff': '.tiff',
            'image/x-emf': '.emf',
            'image/x-wmf': '.wmf',
        }
        return mapping.get(content_type.lower(), '')

    def save_image_data(self, image_data: bytes, filepath: str) -> bool:
        """å°†å›¾ç‰‡å­—èŠ‚å†™å…¥æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'wb') as f:
                f.write(image_data)
            return True
        except Exception as exc:
            logger.warning(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {exc}")
            return False

def print_extraction_summary(result: Dict[str, Any]) -> None:
    """æ‰“å°æå–ç»“æœæ‘˜è¦"""
    if not result.get('success'):
        print(f"âŒ æå–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return
    
    print("=" * 60)
    print("ğŸ‰ é¢˜ç›®æå–å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“Š æ€»é¢˜ç›®æ•°: {result['total_questions']}é“")
    print(f"ğŸ–¼ï¸ æ€»å›¾ç‰‡æ•°: {result['total_images']}å¼ ")
    print(f"ğŸ“š é¢˜å‹æ•°é‡: {len(result['sections'])}ä¸ª")
    
    print("\nğŸ“‹ é¢˜å‹åˆ†å¸ƒ:")
    for section_key, section_info in result['sections'].items():
        print(f"  {section_info['name'][:15]}...: {section_info['count']}é“é¢˜, {section_info['total_images']}å¼ å›¾")
    
    validation = result.get('validation', {})
    issues = validation.get('issues', [])
    success_rate = validation.get('success_rate', 0)
    
    print(f"\nâœ… æˆåŠŸç‡: {success_rate:.1f}%")
    
    if issues:
        print(f"\nâš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("\nğŸ¯ å®Œç¾æå–ï¼Œæ— é—®é¢˜å‘ç°ï¼")
    
    print("=" * 60)


