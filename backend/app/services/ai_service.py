#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç®€åŒ–çš„AIè¯„åˆ†æœåŠ¡ - å®Œå…¨ä¿®å¤ç‰ˆæœ¬
ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½æ˜¯AIç”Ÿæˆï¼Œæ— æ¨¡æ¿åŒ–ä»£ç 
"""

import json
import logging
import re
import sys
import traceback
from typing import Optional, List
from openai import AsyncOpenAI
from ..core.config import settings
from ..schemas.essay import EssayGradingResult, ScoreDetail, DetailedScoreDetail, ScorePoint
from .prompt_service_simple import (
    create_expert_diagnosis_prompt,
    create_overall_evaluation_prompt,
    get_question_type_dimensions
)
from .prompt_service import extract_chapter_content

logger = logging.getLogger(__name__)


def clean_unicode_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®ŠUnicodeå­—ç¬¦"""
    if not text:
        return text
        
    replacements = {
        '\u2014': '--',  # é•¿ç ´æŠ˜å·
        '\u2013': '-',   # çŸ­ç ´æŠ˜å·
        '\u2018': "'",   # å·¦å•å¼•å·
        '\u2019': "'",   # å³å•å¼•å·
        '\u201c': '"',   # å·¦åŒå¼•å·
        '\u201d': '"',   # å³åŒå¼•å·
        '\u2026': '...',  # çœç•¥å·
        '\u00a0': ' ',   # ä¸é—´æ–­ç©ºæ ¼
        '\u2022': 'â€¢',   # é¡¹ç›®ç¬¦å·
    }
    
    for unicode_char, replacement in replacements.items():
        text = text.replace(unicode_char, replacement)
    
    return text


def convert_emoji_to_blue_html(text: str) -> str:
    """å°†è¡¨æƒ…ç¬¦å·æ ¼å¼è½¬æ¢ä¸ºè“è‰²HTMLæ ¼å¼"""
    if not text:
        return text
    
    # è½¬æ¢è¡¨æƒ…ç¬¦å·æ ¼å¼ä¸ºè“è‰²HTMLæ ¼å¼
    replacements = {
        'âœ… **åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        'âŒ **æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        'ğŸ’¡ **æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        'ğŸ’¡ **æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        '**åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        '**æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        '**æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        '**æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        # æ·»åŠ æ›´å¤šå¯èƒ½çš„æ ¼å¼å˜ä½“
        'âœ…**åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        'âŒ**æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        'ğŸ’¡**æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        'ğŸ’¡**æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>'
    }
    
    for old_format, new_format in replacements.items():
        text = text.replace(old_format, new_format)
    
    return text


def extract_meaningful_evaluation_from_raw_content(content: str) -> str:
    """ä»AIåŸå§‹å“åº”ä¸­æ™ºèƒ½æå–è¯„ä»·å†…å®¹ï¼Œä¸“é—¨ç”¨äºæ•´ä½“è¯„ä»·"""
    if not content:
        return ""
    
    # å…ˆå°è¯•ä»å¯èƒ½çš„JSONä¸­æå–
    try:
        # ç®€å•çš„JSONæå–å°è¯•
        if '"overall_evaluation"' in content:
            start = content.find('"overall_evaluation"') + len('"overall_evaluation"')
            # æ‰¾åˆ°åé¢çš„å€¼
            colon_pos = content.find(':', start)
            if colon_pos != -1:
                # ä»å†’å·åå¼€å§‹æ‰¾å€¼
                value_start = colon_pos + 1
                # æ‰¾åˆ°å¼•å·å¼€å§‹
                quote_start = content.find('"', value_start)
                if quote_start != -1:
                    quote_end = content.find('"', quote_start + 1)
                    while quote_end != -1 and content[quote_end - 1] == '\\':
                        quote_end = content.find('"', quote_end + 1)
                    if quote_end != -1:
                        evaluation_text = content[quote_start + 1:quote_end]
                        if evaluation_text and len(evaluation_text) > 20:
                            return evaluation_text.replace('\\n', '\n').strip()
    except Exception:
        pass
    
    # å¦‚æœJSONæå–å¤±è´¥ï¼Œå°è¯•æå–æ˜æ˜¾çš„è¯„ä»·å¥å­
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.]', content)
    evaluation_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        # å¯»æ‰¾åŒ…å«è¯„ä»·å…³é”®è¯çš„å¥å­
        if (len(sentence) > 15 and
            any(keyword in sentence for keyword in ['ç­”æ¡ˆ', 'è¡¨ç°', 'æ°´å¹³', 'èƒ½åŠ›', 'åŸºç¡€', 'æ•´ä½“', 'åˆ†æ', 'è¯„ä»·']) and
            not sentence.startswith('{') and
            not sentence.startswith('"') and
            'è§£æå¤±è´¥' not in sentence):
            evaluation_sentences.append(sentence)
            if len(evaluation_sentences) >= 2:
                break
    
    if evaluation_sentences:
        result = 'ã€‚'.join(evaluation_sentences) + 'ã€‚'
        return result[:500]  # é™åˆ¶é•¿åº¦
    
    return ""


def extract_answer_from_reasoning(reasoning_content: str) -> str:
    """ä»æ¨ç†æ¨¡å‹çš„reasoning_contentä¸­æå–é¢˜å‹ç­”æ¡ˆ"""
    if not reasoning_content:
        return ""
    
    # é¢˜å‹é€‰é¡¹
    valid_types = ["æ¦‚æ‹¬é¢˜", "ç»¼åˆåˆ†æé¢˜", "å¯¹ç­–é¢˜", "åº”ç”¨æ–‡å†™ä½œé¢˜"]
    
    # åœ¨æ¨ç†å†…å®¹ä¸­æŸ¥æ‰¾æ˜ç¡®çš„é¢˜å‹ç­”æ¡ˆ
    for question_type in valid_types:
        if question_type in reasoning_content:
            # æ£€æŸ¥ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ˜¯ä½œä¸ºç­”æ¡ˆè€Œéä¸¾ä¾‹
            type_index = reasoning_content.find(question_type)
            context = reasoning_content[max(0, type_index-50):type_index+50].lower()
            
            # å¦‚æœä¸Šä¸‹æ–‡åŒ…å«ç¡®å®šæ€§è¯æ±‡ï¼Œè®¤ä¸ºæ˜¯ç­”æ¡ˆ
            if any(keyword in context for keyword in ["that's", "ç­”æ¡ˆ", "æ˜¯", "åº”è¯¥", "åˆ¤æ–­", "é€‰æ‹©"]):
                logger.info(f"ä»reasoningä¸­æå–åˆ°ç­”æ¡ˆ: {question_type}")
                return question_type
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®ç­”æ¡ˆï¼Œå°è¯•ä»æ¨ç†é€»è¾‘ä¸­æ¨æ–­
    reasoning_lower = reasoning_content.lower()
    if "comprehensive analysis" in reasoning_lower or "ç»¼åˆåˆ†æ" in reasoning_lower:
        return "ç»¼åˆåˆ†æé¢˜"
    elif "summary" in reasoning_lower or "æ¦‚æ‹¬" in reasoning_lower:
        return "æ¦‚æ‹¬é¢˜"
    elif "policy" in reasoning_lower or "å¯¹ç­–" in reasoning_lower:
        return "å¯¹ç­–é¢˜"
    elif "application" in reasoning_lower or "åº”ç”¨æ–‡" in reasoning_lower:
        return "åº”ç”¨æ–‡å†™ä½œé¢˜"
    
    return ""


def clean_ai_thinking_patterns(text: str) -> str:
    """æ¸…ç†AIæ€è€ƒè¿‡ç¨‹çš„æ¨¡å¼å’ŒpromptæŒ‡ä»¤ï¼Œä½†ä¿ç•™æœ‰ä»·å€¼çš„åˆ†æå†…å®¹"""
    if not text:
        return text
    
    # åªæ£€æŸ¥æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯æ¨¡å¼ï¼Œä¸è¿‡åº¦è¿‡æ»¤
    critical_error_indicators = [
        "è§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹ï¼š",
        "JSONè§£æé”™è¯¯",
        "parse error",
        "failed to parse",
        "dimension_analysis\":",  # JSONç»“æ„ç‰¹å¾
        "\"total_score\":",
        "\"overall_evaluation\":",
        "\"positive_points\":",
        "\"negative_points\":"
    ]
    
    # å¦‚æœåŒ…å«æ˜ç¡®çš„é”™è¯¯æ¨¡å¼ï¼Œæ‰è¿”å›ç©ºå†…å®¹
    if any(indicator in text for indicator in critical_error_indicators):
        logger.warning("æ£€æµ‹åˆ°æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼Œè¿”å›ç©ºå†…å®¹")
        return ""
    
    # åˆ é™¤AIæ€è€ƒè¿‡ç¨‹çš„æ­¥éª¤æ ‡è®°ï¼Œä½†ä¿ç•™åˆ†æå†…å®¹
    patterns = [
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥ï¼š?',
        r'Step\s*\d+:?\s*',
        r'æ­¥éª¤[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ï¼š?',
    ]
    
    # åˆ é™¤promptæŒ‡ä»¤æ³„æ¼
    prompt_leakage_patterns = [
        r'è¯·ä¸¥æ ¼æŒ‰ç…§ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±çš„æ–¹æ³•è®ºï¼Œå¯¹è¯¥ç»´åº¦è¿›è¡Œæ·±åº¦è¯„ä»·ã€‚è¯„ä»·è¦æ±‚ï¼š\s*',
        r'åŸºäºã€Šç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±ã€‹.*?è¯„ä»·è¦æ±‚ï¼š\s*',
        r'ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±.*?æ–¹æ³•è®º.*?è¯„ä»·è¦æ±‚ï¼š\s*',
        r'è¯·ä¸¥æ ¼æŒ‰ç…§.*?æ ¸å¿ƒç§˜ç±.*?è¯„ä»·è¦æ±‚ï¼š\s*',
        r'ä½œä¸ºèµ„æ·±ç”³è®ºé˜…å·ä¸“å®¶["\']?æ‚Ÿé“["\']?çš„.*?[ï¼š:]\s*',
        r'ä½œä¸º.*?é˜…å·ä¸“å®¶.*?çš„.*?[ï¼š:]\s*',
        r'ä½œä¸ºä¸“ä¸šé˜…å·è€å¸ˆå¯¹è¿™ç¯‡.*?ç­”æ¡ˆçš„.*?[ï¼š:]\s*',
        r'æ‚Ÿé“.*?ä¸“ä¸š.*?[ï¼š:]\s*',
        r'æ·±åº¦ä¸“ä¸šè¯Šæ–­[ï¼š:]\s*',
        r'æœ€ç»ˆä¸“ä¸šç‚¹è¯„[ï¼š:]\s*',
    ]
    
    for pattern in patterns + prompt_leakage_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    return text.strip()


async def grade_essay_with_expert_diagnosis(essay_content: str, question_type: Optional[str] = None) -> tuple:
    """
    åŒé˜¶æ®µAIä¸“å®¶è¯Šæ–­å¼è¯„åˆ†
    ç¬¬ä¸€é˜¶æ®µï¼šä¸“ä¸šé˜…å·è€å¸ˆé€å¥è¯Šæ–­
    ç¬¬äºŒé˜¶æ®µï¼šåŸºäºè¯Šæ–­ç”Ÿæˆæ•´ä½“è¯„ä»·
    
    Returns:
        tuple: (ç¬¬ä¸€é˜¶æ®µè¯Šæ–­ç»“æœ, ç¬¬äºŒé˜¶æ®µè¯„ä»·ç»“æœ)
    """
    try:
        client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_api_base,
            default_headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šä¸“ä¸šè¯Šæ–­ =====
        diagnosis_prompt = create_expert_diagnosis_prompt(essay_content, question_type or "æ¦‚æ‹¬é¢˜")
        
        logger.info("å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šAIä¸“å®¶è¯Šæ–­åˆ†æ...")
        diagnosis_response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[
                {
                    "role": "user",
                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç”³è®ºé˜…å·ä¸“å®¶ã€‚è¯·è¿›è¡Œä¸“ä¸šçš„é€å¥æ‰¹æ”¹è¯Šæ–­ã€‚\n\n" + diagnosis_prompt
                }
            ],
            temperature=0.2,
            max_tokens=4096
        )
        
        diagnosis_content = diagnosis_response.choices[0].message.content
        if not diagnosis_content:
            raise ValueError("ç¬¬ä¸€é˜¶æ®µAIè¯Šæ–­è¿”å›ç©ºå“åº”")
        
        # è§£æç¬¬ä¸€é˜¶æ®µç»“æœï¼ˆå®¹é”™ï¼‰
        try:
            diagnosis_data = parse_ai_json_response(diagnosis_content, "è¯Šæ–­é˜¶æ®µ", question_type or "æ¦‚æ‹¬é¢˜")
        except Exception as parse_err:
            logger.warning("è¯Šæ–­é˜¶æ®µJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ: {}".format(str(parse_err)[:200]))
            diagnosis_data = {
                "dimensions": {},
                "summary": clean_ai_thinking_patterns(diagnosis_content) or "AIä¸“å®¶è¯Šæ–­å®Œæˆ",
                "teacher_comments": clean_ai_thinking_patterns(diagnosis_content)[:800]
            }
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šæ•´ä½“è¯„ä»· =====
        evaluation_prompt = create_overall_evaluation_prompt(
            diagnosis_data, essay_content, question_type or "æ¦‚æ‹¬é¢˜"
        )
        
        logger.info("å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ•´ä½“è¯„ä»·ç”Ÿæˆ...")
        evaluation_response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[
                {
                    "role": "user",
                    "content": "è¯·åŸºäºç¬¬ä¸€é˜¶æ®µçš„ä¸“ä¸šè¯Šæ–­ç»“æœï¼Œç”Ÿæˆæ•´ä½“è¯„ä»·ã€‚\n\n" + evaluation_prompt
                }
            ],
            temperature=0.2,
            max_tokens=2048
        )
        
        evaluation_content = evaluation_response.choices[0].message.content
        if not evaluation_content:
            raise ValueError("ç¬¬äºŒé˜¶æ®µæ•´ä½“è¯„ä»·è¿”å›ç©ºå“åº”")
        
        # è§£æç¬¬äºŒé˜¶æ®µç»“æœï¼ˆå®¹é”™ï¼‰
        try:
            evaluation_data = parse_ai_json_response(evaluation_content, "è¯„ä»·é˜¶æ®µ", question_type or "æ¦‚æ‹¬é¢˜")
            logger.info("è¯„ä»·é˜¶æ®µJSONè§£ææˆåŠŸï¼Œoverall_evaluation: {}".format(
                str(evaluation_data.get("overall_evaluation", ""))[:100]))
        except Exception as parse_err2:
            logger.warning("è¯„ä»·é˜¶æ®µJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ: {}".format(str(parse_err2)[:200]))
            evaluation_data = {
                "total_score": 75.0,
                "overall_evaluation": extract_meaningful_evaluation_from_raw_content(evaluation_content) or "AIä¸“å®¶å·²å®Œæˆç»¼åˆè¯„ä¼°ï¼Œè¯·å‚è€ƒè¯¦ç»†çš„ä¸“ä¸šè¯Šæ–­æ„è§",
                "priority_suggestions": [],
                "strengths_to_maintain": [],
                "final_comments": ""
            }
        
        return diagnosis_data, evaluation_data
        
    except Exception as e:
        logger.error("åŒé˜¶æ®µAIè¯Šæ–­å¤±è´¥: {}".format(str(e)))
        raise Exception("AIä¸“å®¶è¯Šæ–­æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {}".format(str(e)[:100]))


async def grade_essay_with_ai(essay_content: str, question_type: Optional[str] = None) -> EssayGradingResult:
    """
    æ–°çš„åŒé˜¶æ®µAIä¸“å®¶è¯„åˆ†ä¸»å‡½æ•°
    æ•´åˆè¯Šæ–­å’Œè¯„ä»·ä¸¤ä¸ªé˜¶æ®µçš„ç»“æœï¼Œç¡®ä¿è¿”å›å¹²å‡€çš„ç”¨æˆ·å‹å¥½å†…å®¹
    """
    try:
        # è°ƒç”¨åŒé˜¶æ®µè¯Šæ–­
        diagnosis_data, evaluation_data = await grade_essay_with_expert_diagnosis(
            essay_content, question_type
        )
        
        # è·å–æ€»åˆ†
        total_score = evaluation_data.get("total_score", 75.0)
        try:
            total_score = float(total_score)
            total_score = max(0, min(100, total_score))
        except (ValueError, TypeError):
            total_score = 75.0
        
        # è·å–æ•´ä½“è¯„ä»· - ç‰¹æ®Šå¤„ç†ï¼Œé¿å…è¯¯æ€æ­£å¸¸å†…å®¹
        overall_evaluation = evaluation_data.get("overall_evaluation", "AIæ‰¹æ”¹å®Œæˆ")
        logger.info("åŸå§‹overall_evaluation: {}".format(str(overall_evaluation)[:150]))
        
        # å¦‚æœæ˜¯ä»JSONæ­£ç¡®è§£æå‡ºæ¥çš„è¯„ä»·å†…å®¹ï¼Œä¸è¦è¿‡åº¦æ¸…ç†
        if overall_evaluation and overall_evaluation != "AIæ‰¹æ”¹å®Œæˆ":
            # åªæ¸…ç†æ˜æ˜¾çš„é”™è¯¯æ¨¡å¼ï¼Œä¿ç•™æ­£å¸¸çš„è¯„ä»·å†…å®¹
            if any(error_pattern in overall_evaluation for error_pattern in ["è§£æå¤±è´¥", "JSONè§£æé”™è¯¯", "parse error"]):
                overall_evaluation = "AIä¸“å®¶å·²å®Œæˆç»¼åˆè¯„ä¼°ï¼Œå…·ä½“åˆ†æè¯·å‚è€ƒä¸“ä¸šè¯Šæ–­æ„è§"
                logger.info("æ£€æµ‹åˆ°é”™è¯¯æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤è¯„ä»·")
            else:
                logger.info("ä¿ç•™åŸå§‹è¯„ä»·å†…å®¹")
            # å…¶ä»–æƒ…å†µä¿ç•™åŸå§‹è¯„ä»·å†…å®¹
        else:
            # ä½¿ç”¨æ›´æœ‰æ„ä¹‰çš„é»˜è®¤è¯„ä»·
            overall_evaluation = "AIä¸“å®¶å·²å®Œæˆç»¼åˆè¯„ä¼°ï¼Œå…·ä½“åˆ†æè¯·å‚è€ƒä¸“ä¸šè¯Šæ–­æ„è§"
            logger.info("ä½¿ç”¨é»˜è®¤è¯„ä»·ï¼ŒåŸå› ï¼šoverall_evaluationä¸ºç©ºæˆ–ä¸ºé»˜è®¤å€¼")
        
        # è·å–å¹¶æ¸…ç†ä¸“ä¸šè¯Šæ–­æ„è§
        teacher_comments = diagnosis_data.get("teacher_comments", "")
        teacher_comments = clean_ai_thinking_patterns(teacher_comments)
        
        # è·å–ç¬¬äºŒé˜¶æ®µçš„è¯¦ç»†ç‚¹è¯„ä½œä¸ºè¡¥å……
        final_comments = evaluation_data.get("final_comments", "")
        final_comments = clean_ai_thinking_patterns(final_comments)
        
        # æ„å»ºæ¸…æ´çš„åé¦ˆå†…å®¹ï¼Œç¡®ä¿ä¸åŒ…å«JSONæˆ–é”™è¯¯ä¿¡æ¯
        feedback_parts = []
        
        if overall_evaluation and len(overall_evaluation.strip()) > 0:
            feedback_parts.append("**æ•´ä½“è¯„ä»·ï¼š**\n{}".format(overall_evaluation))
        else:
            feedback_parts.append("**æ•´ä½“è¯„ä»·ï¼š**\nAIå·²å®Œæˆå¯¹æ‚¨ç­”æ¡ˆçš„ç»¼åˆè¯„ä¼°ï¼Œè¯·å‚è€ƒå…·ä½“è¯„åˆ†ç»†åˆ™è¿›è¡Œæ”¹è¿›ã€‚")
        
        # ä¼˜å…ˆä½¿ç”¨final_commentsï¼Œå¦‚æœæ²¡æœ‰å†ä½¿ç”¨teacher_comments
        detailed_analysis = ""
        if final_comments and len(final_comments.strip()) > 50:
            detailed_analysis = final_comments
        elif teacher_comments and len(teacher_comments.strip()) > 50:
            detailed_analysis = teacher_comments
        
        if detailed_analysis:
            feedback_parts.append("**ä¸“ä¸šè¯Šæ–­æ„è§ï¼š**\n{}".format(detailed_analysis))
        else:
            feedback_parts.append("**ä¸“ä¸šè¯Šæ–­æ„è§ï¼š**\nä¸“å®¶å¯¹æ‚¨çš„ç­”æ¡ˆè¿›è¡Œäº†å…¨é¢åˆ†æï¼Œå…·ä½“å»ºè®®è¯·å‚è€ƒè¯„åˆ†ç»†åˆ™ã€‚")
        
        feedback = "\n\n".join(feedback_parts)
        feedback = clean_unicode_text(feedback)
        
        # è·å–å¹¶æ¸…ç†æ”¹è¿›å»ºè®®
        priority_suggestions = evaluation_data.get("priority_suggestions", [])
        strengths = evaluation_data.get("strengths_to_maintain", [])
        
        # æ¸…ç†å»ºè®®å†…å®¹ï¼Œè¿‡æ»¤åŒ…å«é”™è¯¯ä¿¡æ¯çš„é¡¹ç›®
        cleaned_suggestions = []
        for suggestion in (priority_suggestions + strengths):
            if suggestion and isinstance(suggestion, str):
                cleaned = clean_ai_thinking_patterns(suggestion)
                if cleaned and len(cleaned.strip()) > 10:  # ç¡®ä¿å»ºè®®æœ‰å®è´¨å†…å®¹
                    cleaned_suggestions.append(cleaned)
        
        # ä»è¯Šæ–­æ•°æ®ç›´æ¥æå–è¯„åˆ†ç»†åˆ™
        score_details = convert_diagnosis_to_score_details(diagnosis_data, question_type)
        
        # æ£€æŸ¥è¯„åˆ†ç»†åˆ™ä¸­æ˜¯å¦å·²ç»åŒ…å«æ”¹è¿›å»ºè®®
        has_specific_suggestions = False
        if score_details:
            for detail in score_details:
                if detail.description and any(keyword in detail.description for keyword in ["ã€æ”¹è¿›æ–¹å‘ã€‘", "ã€æ”¹è¿›å»ºè®®ã€‘", "å»ºè®®", "æ”¹è¿›"]):
                    has_specific_suggestions = True
                    break
        
        # åªæœ‰åœ¨è¯„åˆ†ç»†åˆ™ä¸­æ²¡æœ‰å…·ä½“å»ºè®®ä¸”AIä¹Ÿæ²¡æœ‰ç»™å‡ºå»ºè®®æ—¶ï¼Œæ‰æä¾›ç®€åŒ–çš„é»˜è®¤å»ºè®®
        if not cleaned_suggestions and not has_specific_suggestions:
            cleaned_suggestions = ["è¯·å‚è€ƒä¸Šæ–¹è¯„åˆ†ç»†åˆ™ä¸­çš„å…·ä½“æ”¹è¿›å»ºè®®"]
        
        # é™åˆ¶å»ºè®®æ•°é‡
        suggestions = cleaned_suggestions[:5]
        
        # === æ–¹æ¡ˆä¸€ï¼šå¼ºåˆ¶ä¸€è‡´æ€§ - ä½¿ç”¨è¯„åˆ†ç»†åˆ™æ€»åˆ†ä½œä¸ºæœ€ç»ˆæ€»åˆ† ===
        calculated_total = sum(detail.actualScore for detail in score_details) if score_details else 0
        
        # å¦‚æœè¯„åˆ†ç»†åˆ™æœ‰æ•°æ®ä¸”æ€»åˆ†åˆç†ï¼Œä½¿ç”¨è®¡ç®—å‡ºçš„æ€»åˆ†ï¼›å¦åˆ™ä½¿ç”¨AIç»™å‡ºçš„æ€»åˆ†
        if score_details and calculated_total > 0:
            final_total_score = round(calculated_total, 1)
            logger.info("ä½¿ç”¨è¯„åˆ†ç»†åˆ™è®¡ç®—æ€»åˆ†: AIæ€»åˆ†={}, ç»†åˆ™æ€»åˆ†={}, æœ€ç»ˆæ€»åˆ†={}".format(
                total_score, calculated_total, final_total_score))
            
            # è®°å½•åˆ†æ•°å·®å¼‚ç”¨äºç›‘æ§
            score_difference = abs(total_score - calculated_total)
            if score_difference > 5:
                logger.warning("æ€»åˆ†å·®å¼‚è¾ƒå¤§: AIæ€»åˆ†={}, ç»†åˆ™æ€»åˆ†={}, å·®å¼‚={}".format(
                    total_score, calculated_total, score_difference))
        else:
            final_total_score = total_score
            logger.info("ä½¿ç”¨AIæ€»åˆ†: {} (è¯„åˆ†ç»†åˆ™æ•°æ®ä¸è¶³)".format(final_total_score))
        
        return EssayGradingResult(
            score=final_total_score,  # ä½¿ç”¨è®¡ç®—åçš„ä¸€è‡´æ€»åˆ†
            feedback=feedback,
            suggestions=suggestions,
            scoreDetails=score_details
        )
        
    except Exception as e:
        logger.error("AIè¯„åˆ†å¤±è´¥: {}".format(str(e)))
        raise e


def parse_ai_json_response(ai_response: str, stage_name: str, question_type: str = "ç»¼åˆåˆ†æé¢˜") -> dict:
    """ç›´æ¥è§£æAIè¿”å›çš„JSONå“åº”ï¼Œå¦‚æœå¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸"""
    try:
        # è®°å½•AIå“åº”
        logger.info("{}æ”¶åˆ°AIå“åº”ï¼Œé•¿åº¦: {}".format(stage_name, len(ai_response)))
        logger.info("{}AIå“åº”å‰200å­—ç¬¦: {}".format(stage_name, ai_response[:200]))
        
        # å°è¯•è§£æJSONå“åº”
        result_data = try_parse_json_response(ai_response, stage_name)
        if result_data:
            logger.info("{}JSONè§£ææˆåŠŸ".format(stage_name))
            return result_data
        
        # JSONè§£æå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
        logger.error("{}JSONè§£æå¤±è´¥".format(stage_name))
        raise ValueError("AIè¿”å›çš„å†…å®¹æ— æ³•è§£æä¸ºJSONæ ¼å¼: {}".format(ai_response[:200]))
            
    except Exception as e:
        logger.error("{}è§£æè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {}".format(stage_name, str(e)))
        raise e


def try_parse_json_response(ai_response: str, stage_name: str) -> dict:
    """å°è¯•è§£æJSONå“åº”çš„å¤šç§æ–¹æ³•"""
    try:
        # æ¸…ç†å“åº”ä¸­çš„markdownä»£ç å—æ ‡è®°
        cleaned_response = ai_response.strip()
        if cleaned_response.startswith('```json'):
            cleaned_response = cleaned_response[7:]
        if cleaned_response.endswith('```'):
            cleaned_response = cleaned_response[:-3]
        cleaned_response = cleaned_response.strip()
        
        # æ–¹æ³•1: ç›´æ¥è§£æ
        try:
            result = json.loads(cleaned_response)
            logger.info("{}ç›´æ¥JSONè§£ææˆåŠŸ".format(stage_name))
            return result
        except json.JSONDecodeError:
            pass
        
        # æ–¹æ³•2: æŸ¥æ‰¾JSONç»“æ„
        json_start = cleaned_response.find('{')
        json_end = cleaned_response.rfind('}')
        
        if json_start != -1 and json_end != -1 and json_end > json_start:
            json_str = cleaned_response[json_start:json_end + 1]
            
            # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            json_str = json_str.replace('\n', ' ')
            json_str = re.sub(r',\s*}', '}', json_str)
            json_str = re.sub(r',\s*]', ']', json_str)
            
            try:
                result = json.loads(json_str)
                logger.info("{}ç»“æ„åŒ–JSONè§£ææˆåŠŸ".format(stage_name))
                return result
            except json.JSONDecodeError:
                pass
        
        # æ–¹æ³•3: å¤šä¸ªJSONå¯¹è±¡çš„æƒ…å†µ
        json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response)
        if json_objects:
            for json_obj in json_objects:
                try:
                    result = json.loads(json_obj)
                    logger.info("{}å¤šå¯¹è±¡JSONè§£ææˆåŠŸ".format(stage_name))
                    return result
                except json.JSONDecodeError:
                    continue
        
        logger.warning("{}æ‰€æœ‰JSONè§£ææ–¹æ³•éƒ½å¤±è´¥".format(stage_name))
        return None
        
    except Exception as e:
        logger.error("{}JSONè§£æå¼‚å¸¸: {}".format(stage_name, str(e)))
        return None


def convert_diagnosis_to_score_details(diagnosis_data: dict, question_type: str = "æ¦‚æ‹¬é¢˜") -> List[ScoreDetail]:
    """å°†è¯Šæ–­æ•°æ®è½¬æ¢ä¸ºè¯„åˆ†ç»†åˆ™æ ¼å¼"""
    try:
        score_details = []
        
        # ä»è¯Šæ–­æ•°æ®ä¸­æå–ç»´åº¦è¯„ä»·
        dimensions = diagnosis_data.get("dimensions", {})
        
        # è·å–è¯¥é¢˜å‹å¯¹åº”çš„æ»¡åˆ†è®¾ç½®
        question_type_dimensions = get_question_type_dimensions(question_type)
        
        for dimension_name, dimension_info in dimensions.items():
            if isinstance(dimension_info, dict):
                score = dimension_info.get("score", 0)
                feedback = dimension_info.get("feedback", "{}è¯„ä»·".format(dimension_name))
                
                # æ¸…ç†promptæŒ‡ä»¤æ³„æ¼
                feedback = clean_ai_thinking_patterns(feedback)
                
                # è½¬æ¢è¡¨æƒ…ç¬¦å·æ ¼å¼ä¸ºè“è‰²HTMLæ ¼å¼
                feedback = convert_emoji_to_blue_html(feedback)
                
                # ä½¿ç”¨é¢˜å‹å¯¹åº”çš„æ»¡åˆ†ï¼Œå¦‚æœç»´åº¦ä¸å­˜åœ¨åˆ™ä½¿ç”¨25åˆ†é»˜è®¤å€¼
                full_score = question_type_dimensions.get(dimension_name, 25.0)
                
                # åˆ›å»ºè¯„åˆ†ç»†åˆ™å¯¹è±¡ - ä½¿ç”¨é¢˜å‹å¯¹åº”çš„æ»¡åˆ†
                score_detail = ScoreDetail(
                    item=dimension_name,
                    fullScore=float(full_score),
                    actualScore=float(score),
                    description=feedback
                )
                score_details.append(score_detail)
        
        # å¦‚æœæ²¡æœ‰ç»´åº¦æ•°æ®ï¼Œåˆ›å»ºé»˜è®¤çš„è¯„åˆ†ç»†åˆ™
        if not score_details:
            default_feedback = diagnosis_data.get("summary", "AIä¸“å®¶è¯Šæ–­å®Œæˆ")
            score_details.append(ScoreDetail(
                item="ç»¼åˆè¯„ä»·", 
                fullScore=100.0,
                actualScore=75.0,
                description=default_feedback
            ))
        
        return score_details
        
    except Exception as e:
        logger.error("è½¬æ¢è¯Šæ–­æ•°æ®å¤±è´¥: {}".format(str(e)))
        # è¿”å›é»˜è®¤è¯„åˆ†ç»†åˆ™
        return [ScoreDetail(
            item="ç»¼åˆè¯„ä»·",
            fullScore=100.0,
            actualScore=75.0,
            description="AIè¯Šæ–­æ•°æ®è½¬æ¢å¼‚å¸¸"
        )]


async def get_question_type_from_ai(question_text: str) -> str:
    """AIé¢˜å‹è¯Šæ–­æœåŠ¡ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŸºäºç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±"""
    try:
        client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_api_base,
            default_headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )
        
        # ä¸ºé¿å…åç½®ï¼Œä»…ä½¿ç”¨ä¸­ç«‹å®šä¹‰è¿›è¡Œè¯†åˆ«
        prompt = """ä½ æ˜¯ç”³è®ºé¢˜å‹ä¸“å®¶"æ‚Ÿé“"ï¼ŒåŸºäºã€Šç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±ã€‹è¿›è¡Œé¢˜å‹è¯†åˆ«ã€‚

=== ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒè¯†åˆ«è¦ç‚¹ ===
1. **æ¦‚æ‹¬é¢˜**ï¼šè¦æ±‚"æ¦‚æ‹¬"ã€"å½’çº³"ã€"æ¢³ç†"æŸäº›è¦ç‚¹ã€åšæ³•ã€åŸå› ã€å˜åŒ–ç­‰
   - å…³é”®è¯ï¼šæ¦‚æ‹¬ã€å½’çº³ã€æ¢³ç†ã€æ€»ç»“ã€åˆ—ä¸¾
   - ç‰¹å¾ï¼šä¿¡æ¯é™ç»´ä¸é€»è¾‘é‡å»º
   - æ³¨æ„ï¼šé¢˜ç›®é€šå¸¸åªè¦æ±‚åˆ—å‡ºè¦ç‚¹ï¼Œä¸è¦æ±‚æ·±å…¥åˆ†æå…³ç³»
   
2. **ç»¼åˆåˆ†æé¢˜**ï¼šè¦æ±‚"åˆ†æ"ã€"è°ˆè°ˆç†è§£"ã€"è¯„ä»·"ã€"è¯´æ˜"æŸä¸ªè§‚ç‚¹ã€ç°è±¡ã€è¯è¯­
   - å…³é”®è¯ï¼šåˆ†æã€ç†è§£ã€è°ˆè°ˆã€è¯„ä»·ã€å¦‚ä½•çœ‹å¾…ã€è¯´æ˜ã€é˜è¿°ã€è§£é‡Š
   - ç‰¹å¾ï¼šè§£æ„ä¸é‡æ„çš„é€»è¾‘æ€è¾¨
   - æ³¨æ„ï¼šé¢˜ç›®å¾€å¾€è¦æ±‚ä¸ä»…è¯´æ˜"æ˜¯ä»€ä¹ˆ"ï¼Œè¿˜è¦åˆ†æ"ä¸ºä»€ä¹ˆ"ã€"å¦‚ä½•"ç­‰æ·±å±‚å…³ç³»
   
3. **å¯¹ç­–é¢˜**ï¼šè¦æ±‚æå‡º"å¯¹ç­–"ã€"å»ºè®®"ã€"æªæ–½"ã€"æ€ä¹ˆåŠ"
   - å…³é”®è¯ï¼šå¯¹ç­–ã€å»ºè®®ã€æªæ–½ã€åŠæ³•ã€å¦‚ä½•è§£å†³
   - ç‰¹å¾ï¼šå¯¹ç—‡ä¸‹è¯çš„ç²¾å‡†æ–½ç­–
   
4. **åº”ç”¨æ–‡å†™ä½œé¢˜**ï¼šè¦æ±‚å†™"å€¡è®®ä¹¦"ã€"è®²è¯ç¨¿"ã€"æŠ¥å‘Š"ã€"é€šçŸ¥"ç­‰æ ¼å¼åŒ–æ–‡ä½“
   - å…³é”®è¯ï¼šå†™ã€æ‹Ÿã€èµ·è‰ + å…·ä½“æ–‡ç§åç§°
   - ç‰¹å¾ï¼šå¸¦ç€é•£é“çš„åœºæ™¯ä¹‹èˆ

=== å¾…è¯†åˆ«å†…å®¹ ===
{}

=== è¯†åˆ«è¦æ±‚ ===
è¯·ä¸¥æ ¼æŒ‰ç…§ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±çš„æ ‡å‡†ï¼Œåˆ†æä¸Šè¿°å†…å®¹çš„é¢˜å‹ç‰¹å¾ï¼š

1. **å…³é”®åŠ¨è¯è¯†åˆ«**ï¼šé‡ç‚¹å…³æ³¨"è°ˆè°ˆ"ã€"è¯´æ˜"ã€"åˆ†æ"ç­‰è¯æ±‡ï¼ˆè¿™äº›é€šå¸¸æ˜¯ç»¼åˆåˆ†æé¢˜ï¼‰
2. **ä»»åŠ¡å±‚æ¬¡åˆ†æ**ï¼š
   - å¦‚æœåªè¦æ±‚åˆ—å‡ºè¦ç‚¹ â†’ æ¦‚æ‹¬é¢˜
   - å¦‚æœè¦æ±‚è§£é‡Šå«ä¹‰+åˆ†æå…³ç³» â†’ ç»¼åˆåˆ†æé¢˜
   - å¦‚æœè¦æ±‚æå‡ºè§£å†³æ–¹æ¡ˆ â†’ å¯¹ç­–é¢˜
   - å¦‚æœè¦æ±‚å†™ç‰¹å®šæ ¼å¼æ–‡æ¡£ â†’ åº”ç”¨æ–‡å†™ä½œé¢˜
3. **ç‰¹åˆ«æ³¨æ„**ï¼šé¢˜ç›®ä¸­åŒæ—¶å‡ºç°"æ˜¯ä»€ä¹ˆ"+"å¦‚ä½•"+"ä¸ºä»€ä¹ˆ"ç­‰å¤šå±‚æ¬¡è¦æ±‚æ—¶ï¼Œé€šå¸¸æ˜¯ç»¼åˆåˆ†æé¢˜

è¯·åªè¿”å›ä»¥ä¸‹å››ä¸ªé€‰é¡¹ä¸­çš„ä¸€ä¸ªï¼š
- æ¦‚æ‹¬é¢˜
- ç»¼åˆåˆ†æé¢˜  
- å¯¹ç­–é¢˜
- åº”ç”¨æ–‡å†™ä½œé¢˜

åˆ¤æ–­ç»“æœï¼š""".format(question_text)

        response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,  # é™ä½æ¸©åº¦æé«˜å‡†ç¡®æ€§
            max_tokens=200  # å¢åŠ tokené™åˆ¶é¿å…æˆªæ–­
        )
        
        # å¤„ç†æ¨ç†æ¨¡å‹ï¼šä¼˜å…ˆä»reasoning_contentè·å–å“åº”ï¼Œfallbackåˆ°content
        ai_response = response.choices[0].message.content
        reasoning_content = getattr(response.choices[0].message, 'reasoning_content', None)
        
        # å¦‚æœcontentä¸ºç©ºä½†reasoning_contentæœ‰å†…å®¹ï¼Œå°è¯•ä»reasoningä¸­æå–ç­”æ¡ˆ
        if not ai_response and reasoning_content:
            logger.info("æ£€æµ‹åˆ°æ¨ç†æ¨¡å‹ï¼Œä»reasoning_contentæå–ç­”æ¡ˆ")
            ai_response = extract_answer_from_reasoning(reasoning_content)
        
        if not ai_response:
            raise ValueError("AIè¿”å›äº†ç©ºå“åº”")
            
        question_type = ai_response.strip()
        valid_types = ["æ¦‚æ‹¬é¢˜", "ç»¼åˆåˆ†æé¢˜", "å¯¹ç­–é¢˜", "åº”ç”¨æ–‡å†™ä½œé¢˜"]
        
        # ä¼˜å…ˆç²¾ç¡®åŒ¹é…
        for valid_type in valid_types:
            if valid_type == question_type:
                logger.info("AIé¢˜å‹è¯Šæ–­ç»“æœï¼ˆç²¾ç¡®åŒ¹é…ï¼‰: {}".format(valid_type))
                ai_type = valid_type
                break
        else:
            ai_type = None
        
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿›è¡ŒåŒ…å«åŒ¹é…
        for valid_type in valid_types:
            if valid_type in question_type:
                logger.info("AIé¢˜å‹è¯Šæ–­ç»“æœï¼ˆåŒ…å«åŒ¹é…ï¼‰: {}".format(valid_type))
                ai_type = valid_type
                break
        
        # ä»…å¯¹â€œé¢˜ç›®ææ–™åŠé—®é¢˜â€ç‰‡æ®µåšå¯å‘å¼è¯†åˆ«ï¼Œé¿å…è¢«â€œæˆ‘çš„ç­”æ¡ˆâ€å¹²æ‰°
        q_segment = question_text
        try:
            start = question_text.find("ã€é¢˜ç›®ææ–™åŠé—®é¢˜ã€‘")
            answer_pos = question_text.find("ã€æˆ‘çš„ç­”æ¡ˆã€‘")
            if start != -1 and answer_pos != -1 and answer_pos > start:
                q_segment = question_text[start:answer_pos]
        except Exception:
            pass
        question_text_lower = q_segment.lower()
        
        # ç»¼åˆåˆ†æé¢˜çš„è¯†åˆ«ä¼˜å…ˆçº§è¦é«˜ï¼Œå› ä¸ºå®ƒå®¹æ˜“è¢«è¯¯åˆ¤ä¸ºæ¦‚æ‹¬é¢˜
        # å¢å¼ºç‰ˆè¯†åˆ«ï¼šåŒ…å«æ›´å¤šç»¼åˆåˆ†æé¢˜çš„å…³é”®è¯å’Œè¡¨è¾¾æ¨¡å¼
        comprehensive_analysis_keywords = [
            'åˆ†æ', 'ç†è§£', 'è°ˆè°ˆ', 'è¯„ä»·', 'å¦‚ä½•çœ‹å¾…', 'è¯´æ˜', 'é˜è¿°', 'è§£é‡Š',
            'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å…³ç³»', 'ä½œç”¨', 'æ„ä¹‰', 'å½±å“', 'åŸå› '
        ]
        
        summary_keywords = ['æ¦‚æ‹¬', 'å½’çº³', 'æ¢³ç†', 'æ€»ç»“', 'åˆ—ä¸¾']
        strategy_keywords = ['å¯¹ç­–', 'å»ºè®®', 'æªæ–½', 'åŠæ³•', 'å¦‚ä½•è§£å†³', 'æ€ä¹ˆåŠ']
        application_keywords = ['å€¡è®®ä¹¦', 'è®²è¯ç¨¿', 'æŠ¥å‘Š', 'é€šçŸ¥', 'å‘è¨€', 'è‡´è¾', 'å…¬å¼€ä¿¡', 'å†™', 'æ‹Ÿ']
        
        # æ£€æµ‹ç»¼åˆåˆ†æé¢˜çš„å¤åˆç‰¹å¾
        has_comprehensive_keywords = any(keyword in question_text_lower for keyword in comprehensive_analysis_keywords)
        has_multi_layer_requirements = ('æ˜¯ä»€ä¹ˆ' in question_text_lower and 'å¦‚ä½•' in question_text_lower) or \
                                     ('ä»€ä¹ˆ' in question_text_lower and 'è¯´æ˜' in question_text_lower) or \
                                     ('æŒ‡çš„æ˜¯' in question_text_lower and ('å¦‚ä½•' in question_text_lower or 'æ€æ ·' in question_text_lower))
        
        heuristic_type = None  # åˆå§‹åŒ–å˜é‡
        if has_comprehensive_keywords or has_multi_layer_requirements:
            heuristic_type = "ç»¼åˆåˆ†æé¢˜"
            logger.info(f"å¯å‘å¼è¯†åˆ«ä¸ºç»¼åˆåˆ†æé¢˜ï¼Œå…³é”®è¯åŒ¹é…: {has_comprehensive_keywords}, å¤šå±‚æ¬¡è¦æ±‚: {has_multi_layer_requirements}")
        elif any(keyword in question_text_lower for keyword in summary_keywords) and not has_comprehensive_keywords:
            # åªæœ‰åœ¨æ²¡æœ‰åˆ†æç±»è¯æ±‡çš„æƒ…å†µä¸‹æ‰åˆ¤æ–­ä¸ºæ¦‚æ‹¬é¢˜
            heuristic_type = "æ¦‚æ‹¬é¢˜"
        elif any(keyword in question_text_lower for keyword in strategy_keywords):
            heuristic_type = "å¯¹ç­–é¢˜"
        elif any(keyword in question_text_lower for keyword in application_keywords):
            heuristic_type = "åº”ç”¨æ–‡å†™ä½œé¢˜"
        
        logger.info(f"å¯å‘å¼è¯†åˆ«ç»“æœ: {heuristic_type}")
        
        # å†³ç­–ï¼šè‹¥ AI åˆ¤ä¸ºæ¦‚æ‹¬é¢˜ï¼Œä½†å¯å‘å¼å¼ºçƒˆæŒ‡å‘ç»¼åˆåˆ†æé¢˜ï¼Œåˆ™ä»¥å¯å‘å¼ä¸ºå‡†
        if ai_type:
            # ä¿®å¤æ“ä½œç¬¦ä¼˜å…ˆçº§bugï¼šæ·»åŠ æ‹¬å·ç¡®ä¿é€»è¾‘æ­£ç¡®
            if ai_type == "æ¦‚æ‹¬é¢˜" and ('åˆ†æ' in question_text_lower or 'è¯„ä»·' in question_text_lower or 'è°ˆè°ˆ' in question_text_lower or 'è¯´æ˜' in question_text_lower):
                logger.info("è¦†ç›–AIç»“æœï¼šå¯å‘å¼è¯†åˆ«ä¸ºç»¼åˆåˆ†æé¢˜ï¼ˆæ£€æµ‹åˆ°å…³é”®è¯ï¼šåˆ†æ/è¯„ä»·/è°ˆè°ˆ/è¯´æ˜ï¼‰")
                return "ç»¼åˆåˆ†æé¢˜"
            return ai_type
        
        if heuristic_type:
            return heuristic_type
        
        logger.warning("AIé¢˜å‹è¯Šæ–­æœªèƒ½æ˜ç¡®è¯†åˆ«ï¼Œé»˜è®¤è¿”å›æ¦‚æ‹¬é¢˜")
        return "æ¦‚æ‹¬é¢˜"
        
    except Exception as e:
        logger.error("AIé¢˜å‹è¯Šæ–­å¤±è´¥: {}".format(str(e)))
        # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè¦ä½¿ç”¨å¯å‘å¼é€»è¾‘
        logger.info("ä½¿ç”¨å¯å‘å¼é€»è¾‘ä½œä¸ºfallback")
        question_text_lower = question_text.lower()
        
        comprehensive_analysis_keywords = [
            'åˆ†æ', 'ç†è§£', 'è°ˆè°ˆ', 'è¯„ä»·', 'å¦‚ä½•çœ‹å¾…', 'è¯´æ˜', 'é˜è¿°', 'è§£é‡Š',
            'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å…³ç³»', 'ä½œç”¨', 'æ„ä¹‰', 'å½±å“', 'åŸå› '
        ]
        
        if any(keyword in question_text_lower for keyword in comprehensive_analysis_keywords):
            logger.info("å¼‚å¸¸fallbackï¼šè¯†åˆ«ä¸ºç»¼åˆåˆ†æé¢˜")
            return "ç»¼åˆåˆ†æé¢˜"
        
        return "æ¦‚æ‹¬é¢˜"


async def get_ai_service_status() -> dict:
    """æ£€æŸ¥AIæœåŠ¡çŠ¶æ€"""
    try:
        # å¼ºåˆ¶é‡è½½é…ç½®ä»¥è·å–æœ€æ–°å€¼
        settings.reload()
        api_key = settings.openai_api_key
        if not api_key or api_key == "sk-your-openai-api-key-here":
            return {
                "status": "error",
                "message": "OpenAI APIå¯†é’¥æœªæ­£ç¡®é…ç½®"
            }
        
        return {
            "status": "ready",
            "message": "AIæœåŠ¡å·²å°±ç»ª",
            "model": settings.openai_model_name,
            "api_base": settings.openai_api_base
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": "AIæœåŠ¡é…ç½®é”™è¯¯: {}".format(str(e))
        }