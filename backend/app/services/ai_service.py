#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç®€åŒ–çš„AIè¯„åˆ†æœåŠ¡ - å®Œå…¨ä¿®å¤ç‰ˆæœ¬
ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½æ˜¯AIç”Ÿæˆï¼Œæ— æ¨¡æ¿åŒ–ä»£ç 
"""

import json
import logging
import re
import sys
import traceback
from typing import Optional, List
from openai import AsyncOpenAI
from ..core.config import settings
from ..schemas.essay import EssayGradingResult, ScoreDetail, DetailedScoreDetail, ScorePoint
from .prompt_service_simple import (
    create_expert_diagnosis_prompt,
    create_overall_evaluation_prompt,
    get_question_type_dimensions
)
from .prompt_service import extract_chapter_content

logger = logging.getLogger(__name__)


def clean_unicode_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®ŠUnicodeå­—ç¬¦"""
    if not text:
        return text
        
    replacements = {
        '\u2014': '--',  # é•¿ç ´æŠ˜å·
        '\u2013': '-',   # çŸ­ç ´æŠ˜å·
        '\u2018': "'",   # å·¦å•å¼•å·
        '\u2019': "'",   # å³å•å¼•å·
        '\u201c': '"',   # å·¦åŒå¼•å·
        '\u201d': '"',   # å³åŒå¼•å·
        '\u2026': '...',  # çœç•¥å·
        '\u00a0': ' ',   # ä¸é—´æ–­ç©ºæ ¼
        '\u2022': 'â€¢',   # é¡¹ç›®ç¬¦å·
    }
    
    for unicode_char, replacement in replacements.items():
        text = text.replace(unicode_char, replacement)
    
    return text


def convert_emoji_to_blue_html(text: str) -> str:
    """å°†è¡¨æƒ…ç¬¦å·æ ¼å¼è½¬æ¢ä¸ºè“è‰²HTMLæ ¼å¼"""
    if not text:
        return text
    
    # è½¬æ¢è¡¨æƒ…ç¬¦å·æ ¼å¼ä¸ºè“è‰²HTMLæ ¼å¼
    replacements = {
        'âœ… **åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        'âŒ **æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        'ğŸ’¡ **æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        'ğŸ’¡ **æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        '**åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        '**æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        '**æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        '**æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        # æ·»åŠ æ›´å¤šå¯èƒ½çš„æ ¼å¼å˜ä½“
        'âœ…**åŠ åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€å¾—åˆ†ç‚¹ã€‘</span>',
        'âŒ**æ‰£åˆ†ç‚¹ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ‰£åˆ†ç‚¹ã€‘</span>',
        'ğŸ’¡**æ”¹è¿›å»ºè®®ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>',
        'ğŸ’¡**æ”¹è¿›æ–¹å‘ï¼š**': '<span style="color: #1e40af; font-weight: bold;">ã€æ”¹è¿›æ–¹å‘ã€‘</span>'
    }
    
    for old_format, new_format in replacements.items():
        text = text.replace(old_format, new_format)
    
    return text


def clean_ai_thinking_patterns(text: str) -> str:
    """æ¸…ç†AIæ€è€ƒè¿‡ç¨‹çš„æ¨¡å¼ï¼Œä½†ä¿ç•™æœ‰ä»·å€¼çš„åˆ†æå†…å®¹"""
    if not text:
        return text
    
    # åªæ£€æŸ¥æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯æ¨¡å¼ï¼Œä¸è¿‡åº¦è¿‡æ»¤
    critical_error_indicators = [
        "è§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹ï¼š",
        "JSONè§£æé”™è¯¯",
        "parse error",
        "failed to parse",
        "dimension_analysis\":",  # JSONç»“æ„ç‰¹å¾
        "\"total_score\":",
        "\"overall_evaluation\":",
        "\"positive_points\":",
        "\"negative_points\":"
    ]
    
    # å¦‚æœåŒ…å«æ˜ç¡®çš„é”™è¯¯æ¨¡å¼ï¼Œæ‰è¿”å›ç©ºå†…å®¹
    if any(indicator in text for indicator in critical_error_indicators):
        logger.warning("æ£€æµ‹åˆ°æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼Œè¿”å›ç©ºå†…å®¹")
        return ""
    
    # åˆ é™¤AIæ€è€ƒè¿‡ç¨‹çš„æ­¥éª¤æ ‡è®°ï¼Œä½†ä¿ç•™åˆ†æå†…å®¹
    patterns = [
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥ï¼š?',
        r'Step\s*\d+:?\s*',
        r'æ­¥éª¤[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ï¼š?',
    ]
    
    for pattern in patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    return text.strip()


async def grade_essay_with_expert_diagnosis(essay_content: str, question_type: Optional[str] = None) -> tuple:
    """
    åŒé˜¶æ®µAIä¸“å®¶è¯Šæ–­å¼è¯„åˆ†
    ç¬¬ä¸€é˜¶æ®µï¼šä¸“ä¸šé˜…å·è€å¸ˆé€å¥è¯Šæ–­
    ç¬¬äºŒé˜¶æ®µï¼šåŸºäºè¯Šæ–­ç”Ÿæˆæ•´ä½“è¯„ä»·
    
    Returns:
        tuple: (ç¬¬ä¸€é˜¶æ®µè¯Šæ–­ç»“æœ, ç¬¬äºŒé˜¶æ®µè¯„ä»·ç»“æœ)
    """
    try:
        client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_api_base,
            default_headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šä¸“ä¸šè¯Šæ–­ =====
        diagnosis_prompt = create_expert_diagnosis_prompt(essay_content, question_type or "æ¦‚æ‹¬é¢˜")
        
        logger.info("å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šAIä¸“å®¶è¯Šæ–­åˆ†æ...")
        diagnosis_response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[
                {
                    "role": "user",
                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç”³è®ºé˜…å·ä¸“å®¶ã€‚è¯·è¿›è¡Œä¸“ä¸šçš„é€å¥æ‰¹æ”¹è¯Šæ–­ã€‚\n\n" + diagnosis_prompt
                }
            ],
            temperature=0.2,
            max_tokens=4096
        )
        
        diagnosis_content = diagnosis_response.choices[0].message.content
        if not diagnosis_content:
            raise ValueError("ç¬¬ä¸€é˜¶æ®µAIè¯Šæ–­è¿”å›ç©ºå“åº”")
        
        # è§£æç¬¬ä¸€é˜¶æ®µç»“æœ
        diagnosis_data = parse_ai_json_response(diagnosis_content, "è¯Šæ–­é˜¶æ®µ", question_type or "æ¦‚æ‹¬é¢˜")
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šæ•´ä½“è¯„ä»· =====
        evaluation_prompt = create_overall_evaluation_prompt(
            diagnosis_data, essay_content, question_type or "æ¦‚æ‹¬é¢˜"
        )
        
        logger.info("å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ•´ä½“è¯„ä»·ç”Ÿæˆ...")
        evaluation_response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[
                {
                    "role": "user",
                    "content": "è¯·åŸºäºç¬¬ä¸€é˜¶æ®µçš„ä¸“ä¸šè¯Šæ–­ç»“æœï¼Œç”Ÿæˆæ•´ä½“è¯„ä»·ã€‚\n\n" + evaluation_prompt
                }
            ],
            temperature=0.2,
            max_tokens=2048
        )
        
        evaluation_content = evaluation_response.choices[0].message.content
        if not evaluation_content:
            raise ValueError("ç¬¬äºŒé˜¶æ®µæ•´ä½“è¯„ä»·è¿”å›ç©ºå“åº”")
        
        # è§£æç¬¬äºŒé˜¶æ®µç»“æœ
        evaluation_data = parse_ai_json_response(evaluation_content, "è¯„ä»·é˜¶æ®µ", question_type or "æ¦‚æ‹¬é¢˜")
        
        return diagnosis_data, evaluation_data
        
    except Exception as e:
        logger.error("åŒé˜¶æ®µAIè¯Šæ–­å¤±è´¥: {}".format(str(e)))
        raise Exception("AIä¸“å®¶è¯Šæ–­æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {}".format(str(e)[:100]))


async def grade_essay_with_ai(essay_content: str, question_type: Optional[str] = None) -> EssayGradingResult:
    """
    æ–°çš„åŒé˜¶æ®µAIä¸“å®¶è¯„åˆ†ä¸»å‡½æ•°
    æ•´åˆè¯Šæ–­å’Œè¯„ä»·ä¸¤ä¸ªé˜¶æ®µçš„ç»“æœï¼Œç¡®ä¿è¿”å›å¹²å‡€çš„ç”¨æˆ·å‹å¥½å†…å®¹
    """
    try:
        # è°ƒç”¨åŒé˜¶æ®µè¯Šæ–­
        diagnosis_data, evaluation_data = await grade_essay_with_expert_diagnosis(
            essay_content, question_type
        )
        
        # è·å–æ€»åˆ†
        total_score = evaluation_data.get("total_score", 75.0)
        try:
            total_score = float(total_score)
            total_score = max(0, min(100, total_score))
        except (ValueError, TypeError):
            total_score = 75.0
        
        # è·å–å¹¶æ¸…ç†æ•´ä½“è¯„ä»·
        overall_evaluation = evaluation_data.get("overall_evaluation", "AIæ‰¹æ”¹å®Œæˆ")
        overall_evaluation = clean_ai_thinking_patterns(overall_evaluation)
        
        # è·å–å¹¶æ¸…ç†ä¸“ä¸šè¯Šæ–­æ„è§
        teacher_comments = diagnosis_data.get("teacher_comments", "")
        teacher_comments = clean_ai_thinking_patterns(teacher_comments)
        
        # è·å–ç¬¬äºŒé˜¶æ®µçš„è¯¦ç»†ç‚¹è¯„ä½œä¸ºè¡¥å……
        final_comments = evaluation_data.get("final_comments", "")
        final_comments = clean_ai_thinking_patterns(final_comments)
        
        # æ„å»ºæ¸…æ´çš„åé¦ˆå†…å®¹ï¼Œç¡®ä¿ä¸åŒ…å«JSONæˆ–é”™è¯¯ä¿¡æ¯
        feedback_parts = []
        
        if overall_evaluation and len(overall_evaluation.strip()) > 0:
            feedback_parts.append("**æ•´ä½“è¯„ä»·ï¼š**\n{}".format(overall_evaluation))
        else:
            feedback_parts.append("**æ•´ä½“è¯„ä»·ï¼š**\nAIå·²å®Œæˆå¯¹æ‚¨ç­”æ¡ˆçš„ç»¼åˆè¯„ä¼°ï¼Œè¯·å‚è€ƒå…·ä½“è¯„åˆ†ç»†åˆ™è¿›è¡Œæ”¹è¿›ã€‚")
        
        # ä¼˜å…ˆä½¿ç”¨final_commentsï¼Œå¦‚æœæ²¡æœ‰å†ä½¿ç”¨teacher_comments
        detailed_analysis = ""
        if final_comments and len(final_comments.strip()) > 50:
            detailed_analysis = final_comments
        elif teacher_comments and len(teacher_comments.strip()) > 50:
            detailed_analysis = teacher_comments
        
        if detailed_analysis:
            feedback_parts.append("**ä¸“ä¸šè¯Šæ–­æ„è§ï¼š**\n{}".format(detailed_analysis))
        else:
            feedback_parts.append("**ä¸“ä¸šè¯Šæ–­æ„è§ï¼š**\nä¸“å®¶å¯¹æ‚¨çš„ç­”æ¡ˆè¿›è¡Œäº†å…¨é¢åˆ†æï¼Œå…·ä½“å»ºè®®è¯·å‚è€ƒè¯„åˆ†ç»†åˆ™ã€‚")
        
        feedback = "\n\n".join(feedback_parts)
        feedback = clean_unicode_text(feedback)
        
        # è·å–å¹¶æ¸…ç†æ”¹è¿›å»ºè®®
        priority_suggestions = evaluation_data.get("priority_suggestions", [])
        strengths = evaluation_data.get("strengths_to_maintain", [])
        
        # æ¸…ç†å»ºè®®å†…å®¹ï¼Œè¿‡æ»¤åŒ…å«é”™è¯¯ä¿¡æ¯çš„é¡¹ç›®
        cleaned_suggestions = []
        for suggestion in (priority_suggestions + strengths):
            if suggestion and isinstance(suggestion, str):
                cleaned = clean_ai_thinking_patterns(suggestion)
                if cleaned and len(cleaned.strip()) > 10:  # ç¡®ä¿å»ºè®®æœ‰å®è´¨å†…å®¹
                    cleaned_suggestions.append(cleaned)
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå»ºè®®ï¼Œæä¾›é»˜è®¤å»ºè®®
        if not cleaned_suggestions:
            cleaned_suggestions = [
                "å»ºè®®é‡æ–°æ£€æŸ¥ç­”é¢˜æ ¼å¼å’Œé€»è¾‘ç»“æ„", 
                "æ³¨æ„é¢˜ç›®è¦æ±‚çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§",
                "åŠ å¼ºè¦ç‚¹æ¦‚æ‹¬å’Œåˆ†æçš„æ·±åº¦"
            ]
        
        # é™åˆ¶å»ºè®®æ•°é‡
        suggestions = cleaned_suggestions[:5]
        
        # ä»è¯Šæ–­æ•°æ®ç›´æ¥æå–è¯„åˆ†ç»†åˆ™
        score_details = []
        
        # ä½¿ç”¨convert_diagnosis_to_score_detailså‡½æ•°å¤„ç†è¯Šæ–­æ•°æ®
        score_details = convert_diagnosis_to_score_details(diagnosis_data, question_type)
        
        
        return EssayGradingResult(
            score=total_score,
            feedback=feedback,
            suggestions=suggestions,
            scoreDetails=score_details
        )
        
    except Exception as e:
        logger.error("AIè¯„åˆ†å¤±è´¥: {}".format(str(e)))
        raise e


def parse_ai_json_response(ai_response: str, stage_name: str, question_type: str = "ç»¼åˆåˆ†æé¢˜") -> dict:
    """ç›´æ¥è§£æAIè¿”å›çš„JSONå“åº”ï¼Œå¦‚æœå¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸"""
    try:
        # è®°å½•AIå“åº”
        logger.info("{}æ”¶åˆ°AIå“åº”ï¼Œé•¿åº¦: {}".format(stage_name, len(ai_response)))
        logger.info("{}AIå“åº”å‰200å­—ç¬¦: {}".format(stage_name, ai_response[:200]))
        
        # å°è¯•è§£æJSONå“åº”
        result_data = try_parse_json_response(ai_response, stage_name)
        if result_data:
            logger.info("{}JSONè§£ææˆåŠŸ".format(stage_name))
            return result_data
        
        # JSONè§£æå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
        logger.error("{}JSONè§£æå¤±è´¥".format(stage_name))
        raise ValueError("AIè¿”å›çš„å†…å®¹æ— æ³•è§£æä¸ºJSONæ ¼å¼: {}".format(ai_response[:200]))
            
    except Exception as e:
        logger.error("{}è§£æè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {}".format(stage_name, str(e)))
        raise e


def try_parse_json_response(ai_response: str, stage_name: str) -> dict:
    """å°è¯•è§£æJSONå“åº”çš„å¤šç§æ–¹æ³•"""
    try:
        # æ¸…ç†å“åº”ä¸­çš„markdownä»£ç å—æ ‡è®°
        cleaned_response = ai_response.strip()
        if cleaned_response.startswith('```json'):
            cleaned_response = cleaned_response[7:]
        if cleaned_response.endswith('```'):
            cleaned_response = cleaned_response[:-3]
        cleaned_response = cleaned_response.strip()
        
        # æ–¹æ³•1: ç›´æ¥è§£æ
        try:
            result = json.loads(cleaned_response)
            logger.info("{}ç›´æ¥JSONè§£ææˆåŠŸ".format(stage_name))
            return result
        except json.JSONDecodeError:
            pass
        
        # æ–¹æ³•2: æŸ¥æ‰¾JSONç»“æ„
        json_start = cleaned_response.find('{')
        json_end = cleaned_response.rfind('}')
        
        if json_start != -1 and json_end != -1 and json_end > json_start:
            json_str = cleaned_response[json_start:json_end + 1]
            
            # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            json_str = json_str.replace('\n', ' ')
            json_str = re.sub(r',\s*}', '}', json_str)
            json_str = re.sub(r',\s*]', ']', json_str)
            
            try:
                result = json.loads(json_str)
                logger.info("{}ç»“æ„åŒ–JSONè§£ææˆåŠŸ".format(stage_name))
                return result
            except json.JSONDecodeError:
                pass
        
        # æ–¹æ³•3: å¤šä¸ªJSONå¯¹è±¡çš„æƒ…å†µ
        json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response)
        if json_objects:
            for json_obj in json_objects:
                try:
                    result = json.loads(json_obj)
                    logger.info("{}å¤šå¯¹è±¡JSONè§£ææˆåŠŸ".format(stage_name))
                    return result
                except json.JSONDecodeError:
                    continue
        
        logger.warning("{}æ‰€æœ‰JSONè§£ææ–¹æ³•éƒ½å¤±è´¥".format(stage_name))
        return None
        
    except Exception as e:
        logger.error("{}JSONè§£æå¼‚å¸¸: {}".format(stage_name, str(e)))
        return None


def convert_diagnosis_to_score_details(diagnosis_data: dict, question_type: str = "æ¦‚æ‹¬é¢˜") -> List[ScoreDetail]:
    """å°†è¯Šæ–­æ•°æ®è½¬æ¢ä¸ºè¯„åˆ†ç»†åˆ™æ ¼å¼"""
    try:
        score_details = []
        
        # ä»è¯Šæ–­æ•°æ®ä¸­æå–ç»´åº¦è¯„ä»·
        dimensions = diagnosis_data.get("dimensions", {})
        
        # è·å–è¯¥é¢˜å‹å¯¹åº”çš„æ»¡åˆ†è®¾ç½®
        question_type_dimensions = get_question_type_dimensions(question_type)
        
        for dimension_name, dimension_info in dimensions.items():
            if isinstance(dimension_info, dict):
                score = dimension_info.get("score", 0)
                feedback = dimension_info.get("feedback", "{}è¯„ä»·".format(dimension_name))
                
                # è½¬æ¢è¡¨æƒ…ç¬¦å·æ ¼å¼ä¸ºè“è‰²HTMLæ ¼å¼
                feedback = convert_emoji_to_blue_html(feedback)
                
                # ä½¿ç”¨é¢˜å‹å¯¹åº”çš„æ»¡åˆ†ï¼Œå¦‚æœç»´åº¦ä¸å­˜åœ¨åˆ™ä½¿ç”¨25åˆ†é»˜è®¤å€¼
                full_score = question_type_dimensions.get(dimension_name, 25.0)
                
                # åˆ›å»ºè¯„åˆ†ç»†åˆ™å¯¹è±¡ - ä½¿ç”¨é¢˜å‹å¯¹åº”çš„æ»¡åˆ†
                score_detail = ScoreDetail(
                    item=dimension_name,
                    fullScore=float(full_score),
                    actualScore=float(score),
                    description=feedback
                )
                score_details.append(score_detail)
        
        # å¦‚æœæ²¡æœ‰ç»´åº¦æ•°æ®ï¼Œåˆ›å»ºé»˜è®¤çš„è¯„åˆ†ç»†åˆ™
        if not score_details:
            default_feedback = diagnosis_data.get("summary", "AIä¸“å®¶è¯Šæ–­å®Œæˆ")
            score_details.append(ScoreDetail(
                item="ç»¼åˆè¯„ä»·", 
                fullScore=100.0,
                actualScore=75.0,
                description=default_feedback
            ))
        
        return score_details
        
    except Exception as e:
        logger.error("è½¬æ¢è¯Šæ–­æ•°æ®å¤±è´¥: {}".format(str(e)))
        # è¿”å›é»˜è®¤è¯„åˆ†ç»†åˆ™
        return [ScoreDetail(
            item="ç»¼åˆè¯„ä»·",
            fullScore=100.0,
            actualScore=75.0,
            description="AIè¯Šæ–­æ•°æ®è½¬æ¢å¼‚å¸¸"
        )]


async def get_question_type_from_ai(question_text: str) -> str:
    """AIé¢˜å‹è¯Šæ–­æœåŠ¡ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŸºäºç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±"""
    try:
        client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_api_base,
            default_headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )
        
        # è·å–ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±çš„å†…å®¹
        chapter_content = extract_chapter_content("æ¦‚æ‹¬é¢˜")  # è·å–æ¦‚æ‹¬é¢˜ç« èŠ‚ä½œä¸ºå‚è€ƒ
        
        prompt = """ä½ æ˜¯ç”³è®ºé¢˜å‹ä¸“å®¶"æ‚Ÿé“"ï¼ŒåŸºäºã€Šç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±ã€‹è¿›è¡Œé¢˜å‹è¯†åˆ«ã€‚

=== ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒè¯†åˆ«è¦ç‚¹ ===
1. **æ¦‚æ‹¬é¢˜**ï¼šè¦æ±‚"æ¦‚æ‹¬"ã€"å½’çº³"ã€"æ¢³ç†"æŸäº›è¦ç‚¹ã€åšæ³•ã€åŸå› ã€å˜åŒ–ç­‰
   - å…³é”®è¯ï¼šæ¦‚æ‹¬ã€å½’çº³ã€æ¢³ç†ã€æ€»ç»“ã€åˆ—ä¸¾
   - ç‰¹å¾ï¼šä¿¡æ¯é™ç»´ä¸é€»è¾‘é‡å»º
   - æ³¨æ„ï¼šé¢˜ç›®é€šå¸¸åªè¦æ±‚åˆ—å‡ºè¦ç‚¹ï¼Œä¸è¦æ±‚æ·±å…¥åˆ†æå…³ç³»
   
2. **ç»¼åˆåˆ†æé¢˜**ï¼šè¦æ±‚"åˆ†æ"ã€"è°ˆè°ˆç†è§£"ã€"è¯„ä»·"ã€"è¯´æ˜"æŸä¸ªè§‚ç‚¹ã€ç°è±¡ã€è¯è¯­
   - å…³é”®è¯ï¼šåˆ†æã€ç†è§£ã€è°ˆè°ˆã€è¯„ä»·ã€å¦‚ä½•çœ‹å¾…ã€è¯´æ˜ã€é˜è¿°ã€è§£é‡Š
   - ç‰¹å¾ï¼šè§£æ„ä¸é‡æ„çš„é€»è¾‘æ€è¾¨
   - æ³¨æ„ï¼šé¢˜ç›®å¾€å¾€è¦æ±‚ä¸ä»…è¯´æ˜"æ˜¯ä»€ä¹ˆ"ï¼Œè¿˜è¦åˆ†æ"ä¸ºä»€ä¹ˆ"ã€"å¦‚ä½•"ç­‰æ·±å±‚å…³ç³»
   
3. **å¯¹ç­–é¢˜**ï¼šè¦æ±‚æå‡º"å¯¹ç­–"ã€"å»ºè®®"ã€"æªæ–½"ã€"æ€ä¹ˆåŠ"
   - å…³é”®è¯ï¼šå¯¹ç­–ã€å»ºè®®ã€æªæ–½ã€åŠæ³•ã€å¦‚ä½•è§£å†³
   - ç‰¹å¾ï¼šå¯¹ç—‡ä¸‹è¯çš„ç²¾å‡†æ–½ç­–
   
4. **åº”ç”¨æ–‡å†™ä½œé¢˜**ï¼šè¦æ±‚å†™"å€¡è®®ä¹¦"ã€"è®²è¯ç¨¿"ã€"æŠ¥å‘Š"ã€"é€šçŸ¥"ç­‰æ ¼å¼åŒ–æ–‡ä½“
   - å…³é”®è¯ï¼šå†™ã€æ‹Ÿã€èµ·è‰ + å…·ä½“æ–‡ç§åç§°
   - ç‰¹å¾ï¼šå¸¦ç€é•£é“çš„åœºæ™¯ä¹‹èˆ

=== å¾…è¯†åˆ«å†…å®¹ ===
{}

=== è¯†åˆ«è¦æ±‚ ===
è¯·ä¸¥æ ¼æŒ‰ç…§ç”³è®ºå››å¤§é¢˜å‹æ ¸å¿ƒç§˜ç±çš„æ ‡å‡†ï¼Œåˆ†æä¸Šè¿°å†…å®¹çš„é¢˜å‹ç‰¹å¾ï¼š

1. **å…³é”®åŠ¨è¯è¯†åˆ«**ï¼šé‡ç‚¹å…³æ³¨"è°ˆè°ˆ"ã€"è¯´æ˜"ã€"åˆ†æ"ç­‰è¯æ±‡ï¼ˆè¿™äº›é€šå¸¸æ˜¯ç»¼åˆåˆ†æé¢˜ï¼‰
2. **ä»»åŠ¡å±‚æ¬¡åˆ†æ**ï¼š
   - å¦‚æœåªè¦æ±‚åˆ—å‡ºè¦ç‚¹ â†’ æ¦‚æ‹¬é¢˜
   - å¦‚æœè¦æ±‚è§£é‡Šå«ä¹‰+åˆ†æå…³ç³» â†’ ç»¼åˆåˆ†æé¢˜
   - å¦‚æœè¦æ±‚æå‡ºè§£å†³æ–¹æ¡ˆ â†’ å¯¹ç­–é¢˜
   - å¦‚æœè¦æ±‚å†™ç‰¹å®šæ ¼å¼æ–‡æ¡£ â†’ åº”ç”¨æ–‡å†™ä½œé¢˜
3. **ç‰¹åˆ«æ³¨æ„**ï¼šé¢˜ç›®ä¸­åŒæ—¶å‡ºç°"æ˜¯ä»€ä¹ˆ"+"å¦‚ä½•"+"ä¸ºä»€ä¹ˆ"ç­‰å¤šå±‚æ¬¡è¦æ±‚æ—¶ï¼Œé€šå¸¸æ˜¯ç»¼åˆåˆ†æé¢˜

è¯·åªè¿”å›ä»¥ä¸‹å››ä¸ªé€‰é¡¹ä¸­çš„ä¸€ä¸ªï¼š
- æ¦‚æ‹¬é¢˜
- ç»¼åˆåˆ†æé¢˜  
- å¯¹ç­–é¢˜
- åº”ç”¨æ–‡å†™ä½œé¢˜

åˆ¤æ–­ç»“æœï¼š""".format(question_text)

        response = await client.chat.completions.create(
            model=settings.openai_model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,  # é™ä½æ¸©åº¦æé«˜å‡†ç¡®æ€§
            max_tokens=50
        )
        
        ai_response = response.choices[0].message.content
        if not ai_response:
            raise ValueError("AIè¿”å›äº†ç©ºå“åº”")
            
        question_type = ai_response.strip()
        valid_types = ["æ¦‚æ‹¬é¢˜", "ç»¼åˆåˆ†æé¢˜", "å¯¹ç­–é¢˜", "åº”ç”¨æ–‡å†™ä½œé¢˜"]
        
        # ä¼˜å…ˆç²¾ç¡®åŒ¹é…
        for valid_type in valid_types:
            if valid_type == question_type:
                logger.info("AIé¢˜å‹è¯Šæ–­ç»“æœï¼ˆç²¾ç¡®åŒ¹é…ï¼‰: {}".format(valid_type))
                return valid_type
        
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿›è¡ŒåŒ…å«åŒ¹é…
        for valid_type in valid_types:
            if valid_type in question_type:
                logger.info("AIé¢˜å‹è¯Šæ–­ç»“æœï¼ˆåŒ…å«åŒ¹é…ï¼‰: {}".format(valid_type))
                return valid_type
        
        # å¦‚æœéƒ½æ²¡åŒ¹é…åˆ°ï¼Œæ ¹æ®å…³é”®è¯è¿›è¡Œæ™ºèƒ½åˆ¤æ–­
        question_text_lower = question_text.lower()
        
        # ç»¼åˆåˆ†æé¢˜çš„è¯†åˆ«ä¼˜å…ˆçº§è¦é«˜ï¼Œå› ä¸ºå®ƒå®¹æ˜“è¢«è¯¯åˆ¤ä¸ºæ¦‚æ‹¬é¢˜
        if any(keyword in question_text_lower for keyword in ['åˆ†æ', 'ç†è§£', 'è°ˆè°ˆ', 'è¯„ä»·', 'å¦‚ä½•çœ‹å¾…', 'è¯´æ˜', 'é˜è¿°', 'è§£é‡Š']):
            return "ç»¼åˆåˆ†æé¢˜"
        elif any(keyword in question_text_lower for keyword in ['æ¦‚æ‹¬', 'å½’çº³', 'æ¢³ç†', 'æ€»ç»“', 'åˆ—ä¸¾']) and not any(keyword in question_text_lower for keyword in ['è°ˆè°ˆ', 'è¯´æ˜', 'åˆ†æ']):
            # åªæœ‰åœ¨æ²¡æœ‰åˆ†æç±»è¯æ±‡çš„æƒ…å†µä¸‹æ‰åˆ¤æ–­ä¸ºæ¦‚æ‹¬é¢˜
            return "æ¦‚æ‹¬é¢˜"
        elif any(keyword in question_text_lower for keyword in ['å¯¹ç­–', 'å»ºè®®', 'æªæ–½', 'åŠæ³•', 'å¦‚ä½•è§£å†³', 'æ€ä¹ˆåŠ']):
            return "å¯¹ç­–é¢˜"
        elif any(keyword in question_text_lower for keyword in ['å€¡è®®ä¹¦', 'è®²è¯ç¨¿', 'æŠ¥å‘Š', 'é€šçŸ¥', 'å‘è¨€', 'è‡´è¾', 'å…¬å¼€ä¿¡', 'å†™', 'æ‹Ÿ']):
            return "åº”ç”¨æ–‡å†™ä½œé¢˜"
        
        logger.warning("AIé¢˜å‹è¯Šæ–­æœªèƒ½æ˜ç¡®è¯†åˆ«ï¼Œé»˜è®¤è¿”å›æ¦‚æ‹¬é¢˜")
        return "æ¦‚æ‹¬é¢˜"
        
    except Exception as e:
        logger.error("AIé¢˜å‹è¯Šæ–­å¤±è´¥: {}".format(str(e)))
        return "æ¦‚æ‹¬é¢˜"


async def get_ai_service_status() -> dict:
    """æ£€æŸ¥AIæœåŠ¡çŠ¶æ€"""
    try:
        # å¼ºåˆ¶é‡è½½é…ç½®ä»¥è·å–æœ€æ–°å€¼
        settings.reload()
        api_key = settings.openai_api_key
        if not api_key or api_key == "sk-your-openai-api-key-here":
            return {
                "status": "error",
                "message": "OpenAI APIå¯†é’¥æœªæ­£ç¡®é…ç½®"
            }
        
        return {
            "status": "ready",
            "message": "AIæœåŠ¡å·²å°±ç»ª",
            "model": settings.openai_model_name,
            "api_base": settings.openai_api_base
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": "AIæœåŠ¡é…ç½®é”™è¯¯: {}".format(str(e))
        }