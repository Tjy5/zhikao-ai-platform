# ç»™æ–°AIçš„å…³é”®è¡¥å……ä¿¡æ¯

## â— é‡è¦è­¦å‘Š
**å¦‚æœä½ çœ‹åˆ°è¿™ä¸ªæ–‡æ¡£ï¼Œè¯´æ˜æœ‰äººè®©ä½ åŸºäº`é¢˜ç›®æå–æ–¹æ¡ˆ.md`æ¥å®ç°é¢˜ç›®æå–åŠŸèƒ½ã€‚è¯·åŠ¡å¿…é˜…è¯»è¿™ä¸ªè¡¥å……æ–‡æ¡£ï¼Œå®ƒåŒ…å«äº†å…³é”®çš„å®ç°ç»†èŠ‚å’Œè¡€æ³ªæ•™è®­ã€‚**

---

## ğŸ¯ æ ¸å¿ƒè®¤çŸ¥çªç ´ï¼ˆå¿…é¡»ç†è§£ï¼‰

### æœ€é‡è¦çš„æ´å¯Ÿ
> **"å›¾ç‰‡åˆ†ç±»æ˜¯ä¼ªéœ€æ±‚ï¼Œé¢˜ç›®å®Œæ•´æ€§æ‰æ˜¯çœŸéœ€æ±‚ï¼"**

**é”™è¯¯æ€è·¯**ï¼ˆåƒä¸‡ä¸è¦è¿™æ ·æƒ³ï¼‰ï¼š
- âŒ "è¿™å¼ å›¾ç‰‡æ˜¯é¢˜å¹²å›¾è¿˜æ˜¯é€‰é¡¹å›¾ï¼Ÿ"
- âŒ "è¿™å¼ å›¾ç‰‡å±äºå¤§é¢˜ææ–™è¿˜æ˜¯å°é¢˜å†…å®¹ï¼Ÿ"  
- âŒ "å›¾ç‰‡Aå±äºé€‰é¡¹Aè¿˜æ˜¯é€‰é¡¹Bï¼Ÿ"
- âŒ "éœ€è¦AIåˆ†æå›¾ç‰‡å’Œæ–‡å­—çš„è¯­ä¹‰å…³ç³»"

**æ­£ç¡®æ€è·¯**ï¼ˆåƒäººç±»ä¸€æ ·æ€è€ƒï¼‰ï¼š
- âœ… "é¢˜ç›®1ä»ç¼–å·'1'å¼€å§‹ï¼Œåˆ°ç¼–å·'2'ç»“æŸ"
- âœ… "ä¸­é—´æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬å›¾ç‰‡ï¼‰éƒ½å±äºé¢˜ç›®1"
- âœ… "å›¾ç‰‡éšæ®µè½è‡ªåŠ¨å½’å±ï¼Œä¸éœ€è¦å¤æ‚åˆ†ç±»"
- âœ… "äººç±»å¤åˆ¶ç²˜è´´å°±æ˜¯è¿™æ ·åšçš„"

---

## ğŸ“Š å®é™…æ–‡æ¡£ç»“æ„ï¼ˆå®æµ‹æ•°æ®ï¼‰

### çœŸå®å‘ç°
```
æ€»æ®µè½æ•°: 946ä¸ª
é¢˜ç›®æ•°é‡: 135é“ (ç¼–å·1-135)
æ€»å›¾ç‰‡æ•°: 3288å¼  (ä¸æ˜¯600+å¼ ï¼)
é€‰é¡¹æ•°é‡: 540ä¸ª (135Ã—4ï¼Œå®Œå…¨å¯¹ç§°)

é¢˜å‹åˆ†å¸ƒï¼ˆå®æµ‹ï¼‰ï¼š
ğŸ“š ä¸€ã€æ”¿æ²»ç†è®ºï¼š20é“é¢˜ (æ®µè½2-141)
ğŸ“š äºŒã€å¸¸è¯†åˆ¤æ–­ï¼š15é“é¢˜ (æ®µè½141-241)  
ğŸ“š ä¸‰ã€è¨€è¯­ç†è§£ä¸è¡¨è¾¾ï¼š30é“é¢˜ (æ®µè½241-464)
ğŸ“š å››ã€æ•°é‡å…³ç³»ï¼š15é“é¢˜ (æ®µè½464-556)
ğŸ“š äº”ã€åˆ¤æ–­æ¨ç†ï¼š55é“é¢˜ (æ®µè½556-946)

æ€»è®¡ï¼š20+15+30+15+55 = 135é“é¢˜ âœ“
```

### é¢˜ç›®é—´éš”è§„å¾‹
```
å¤§å¤šæ•°é¢˜ç›®é—´éš”ï¼š6æ®µè½ (67æ¬¡å‡ºç°)
æ­£å¸¸é¢˜ç›®é—´éš”ï¼š7æ®µè½ (51æ¬¡å‡ºç°)
å¤§é¢˜è¾¹ç•Œæ ‡å¿—ï¼š15æ®µè½é—´éš” (åœ¨ç¬¬60â†’61é¢˜ã€115â†’116é¢˜)
```

### æ ‡å‡†é¢˜ç›®ç»“æ„æ¨¡å¼
```python
# ä»¥é¢˜ç›®1ä¸ºä¾‹çš„çœŸå®ç»“æ„ï¼š
æ®µè½4:   "1"           (é¢˜ç›®ç¼–å·ï¼Œ1å¼ å›¾ç‰‡)
æ®µè½5:   é¢˜å¹²å†…å®¹       (1å¼ å›¾ç‰‡)
æ®µè½6:   "â‘ XXX"        (å†…å®¹é€‰é¡¹1ï¼Œ2å¼ å›¾ç‰‡)  
æ®µè½7:   "â‘¡XXX"        (å†…å®¹é€‰é¡¹2ï¼Œ2å¼ å›¾ç‰‡)
æ®µè½8:   "â‘¢XXX"        (å†…å®¹é€‰é¡¹3ï¼Œ2å¼ å›¾ç‰‡)
æ®µè½9:   "â‘£XXX"        (å†…å®¹é€‰é¡¹4ï¼Œ2å¼ å›¾ç‰‡)
æ®µè½10:  "Aã€â‘ â‘¡"      (ç­”æ¡ˆé€‰é¡¹Aï¼Œ3å¼ å›¾ç‰‡)
æ®µè½11:  "Bã€â‘ â‘¢"      (ç­”æ¡ˆé€‰é¡¹Bï¼Œ3å¼ å›¾ç‰‡)  
æ®µè½12:  "Cã€â‘¡â‘£"      (ç­”æ¡ˆé€‰é¡¹Cï¼Œ3å¼ å›¾ç‰‡)
æ®µè½13:  "Dã€â‘¢â‘£"      (ç­”æ¡ˆé€‰é¡¹Dï¼Œ3å¼ å›¾ç‰‡)
```

**æ³¨æ„**ï¼šä¸æ˜¯æ‰€æœ‰é¢˜ç›®éƒ½æœ‰â‘ â‘¡â‘¢â‘£ç»“æ„ï¼æœ‰äº›é¢˜ç›®ç›´æ¥æ˜¯ABCDé€‰é¡¹ã€‚

---

## ğŸ’» å…·ä½“å®ç°ä»£ç ï¼ˆå¯ç›´æ¥ä½¿ç”¨ï¼‰

### æ ¸å¿ƒæå–å™¨
```python
from docx import Document
import re
import os

class HumanLogicQuestionExtractor:
    """åŸºäºäººç±»é€»è¾‘çš„é¢˜ç›®æå–å™¨"""
    
    def __init__(self):
        self.section_pattern = r'^[ä¸€äºŒä¸‰å››äº”]ã€'
        self.question_pattern = r'^\d+$'
        
    def extract_questions(self, docx_path):
        """ä¸»æå–å‡½æ•°"""
        doc = Document(docx_path)
        
        # ç¬¬1æ­¥ï¼šæ‰¾åˆ°æ‰€æœ‰é¢˜å‹åˆ†ç•Œç‚¹
        sections = self.find_sections(doc)
        print(f"æ‰¾åˆ° {len(sections)} ä¸ªé¢˜å‹")
        
        # ç¬¬2æ­¥ï¼šåœ¨æ¯ä¸ªé¢˜å‹å†…æ‰¾é¢˜ç›®
        for section in sections:
            section['questions'] = self.find_questions_in_section(doc, section)
            print(f"{section['name']}: {len(section['questions'])}é“é¢˜")
        
        # ç¬¬3æ­¥ï¼šæå–æ¯é“é¢˜çš„å®Œæ•´å†…å®¹
        all_questions = []
        for section in sections:
            for question in section['questions']:
                content = self.extract_question_content(doc, question)
                all_questions.append({
                    'number': question['number'],
                    'section': section['name'],
                    'content': content,
                    'paragraph_range': f"{question['start']}-{question['end']}"
                })
        
        return all_questions
    
    def find_sections(self, doc):
        """æ‰¾é¢˜å‹è¾¹ç•Œ"""
        sections = []
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if re.match(self.section_pattern, text):
                sections.append({
                    'name': text,
                    'start_para': i
                })
        
        # ç¡®å®šæ¯ä¸ªé¢˜å‹çš„ç»“æŸä½ç½®
        for i in range(len(sections)):
            if i + 1 < len(sections):
                sections[i]['end_para'] = sections[i + 1]['start_para']
            else:
                sections[i]['end_para'] = len(doc.paragraphs)
        
        return sections
    
    def find_questions_in_section(self, doc, section):
        """åœ¨é¢˜å‹å†…æ‰¾é¢˜ç›®ç¼–å·"""
        questions = []
        
        for i in range(section['start_para'], section['end_para']):
            if i < len(doc.paragraphs):
                text = doc.paragraphs[i].text.strip()
                if re.match(self.question_pattern, text):
                    questions.append({
                        'number': int(text),
                        'start': i
                    })
        
        # ç¡®å®šæ¯é“é¢˜çš„ç»“æŸä½ç½®
        for j in range(len(questions)):
            if j + 1 < len(questions):
                questions[j]['end'] = questions[j + 1]['start']
            else:
                questions[j]['end'] = section['end_para']
        
        return questions
    
    def extract_question_content(self, doc, question):
        """æå–é¢˜ç›®çš„å®Œæ•´å†…å®¹"""
        content = []
        total_images = 0
        
        for para_idx in range(question['start'], question['end']):
            if para_idx < len(doc.paragraphs):
                para = doc.paragraphs[para_idx]
                para_text = para.text.strip()
                
                # ç»Ÿè®¡å›¾ç‰‡ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰
                para_images = 0
                for run in para.runs:
                    if hasattr(run._element, 'xml'):
                        xml_str = str(run._element.xml)
                        if 'pic:pic' in xml_str or 'drawing' in xml_str:
                            para_images += 1
                
                total_images += para_images
                
                if para_text or para_images > 0:
                    content.append({
                        'paragraph_index': para_idx,
                        'text': para_text,
                        'images_count': para_images
                    })
        
        return {
            'paragraphs': content,
            'total_images': total_images
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    extractor = HumanLogicQuestionExtractor()
    questions = extractor.extract_questions(
        r"é¢˜ç›®\2025å¹´å›½å®¶å…¬åŠ¡å‘˜å½•ç”¨è€ƒè¯•ã€Šè¡Œæµ‹ã€‹é¢˜ï¼ˆå‰¯çœçº§ç½‘å‹å›å¿†ç‰ˆï¼‰.docx"
    )
    
    print(f"\n=== æå–ç»“æœ ===")
    print(f"æ€»å…±æå– {len(questions)} é“é¢˜ç›®")
    
    # éªŒè¯æ•°é‡
    section_counts = {}
    for q in questions:
        section_name = q['section'][:5]  # å–å‰5ä¸ªå­—ç¬¦
        section_counts[section_name] = section_counts.get(section_name, 0) + 1
    
    print("é¢˜å‹åˆ†å¸ƒ:")
    for section, count in section_counts.items():
        print(f"  {section}: {count}é“é¢˜")
```

---

## ğŸš¨ å…³é”®å®ç°è¦ç‚¹

### 1. é¢˜å‹è¯†åˆ«ï¼ˆ100%å‡†ç¡®ï¼‰
```python
# å¯»æ‰¾è¿™5ä¸ªæ˜ç¡®æ ‡è¯†
patterns = [
    "ä¸€ã€æ”¿æ²»ç†è®º",
    "äºŒã€å¸¸è¯†åˆ¤æ–­", 
    "ä¸‰ã€è¨€è¯­ç†è§£ä¸è¡¨è¾¾",
    "å››ã€æ•°é‡å…³ç³»",
    "äº”ã€åˆ¤æ–­æ¨ç†"
]
```

### 2. é¢˜ç›®è¾¹ç•Œè¯†åˆ«ï¼ˆ99%å‡†ç¡®ï¼‰
```python
# ç‹¬ç«‹æ•°å­—æ®µè½å°±æ˜¯é¢˜ç›®ç¼–å·
if re.match(r'^\d+$', paragraph_text.strip()):
    # è¿™æ˜¯é¢˜ç›®ç¼–å·ï¼Œä»è¿™é‡Œå¼€å§‹åˆ°ä¸‹ä¸€ä¸ªç¼–å·å°±æ˜¯å®Œæ•´é¢˜ç›®
```

### 3. å›¾ç‰‡æå–ç­–ç•¥
```python
# ä¸è¦çº ç»“å›¾ç‰‡åˆ†ç±»ï¼Œç›´æ¥æå–ä½ç½®ä¿¡æ¯
def extract_images_with_position(paragraph):
    images = []
    for run in paragraph.runs:
        if 'pic:pic' in str(run._element.xml):
            images.append({
                'position_in_paragraph': len(images),
                # å¯ä»¥ä¿å­˜å›¾ç‰‡æ•°æ®ï¼Œä½†ä¸éœ€è¦åˆ¤æ–­"ç±»å‹"
            })
    return images
```

---

## âš ï¸ é¿å…çš„é™·é˜±

### é™·é˜±1ï¼šè¿‡åº¦åˆ†æå›¾ç‰‡ç±»å‹
```python
# âŒ é”™è¯¯åšæ³•
def classify_image_type(image):
    if is_material_image(image):
        return 'material'
    elif is_question_image(image):
        return 'question'
    # ... å¤æ‚åˆ†ç±»é€»è¾‘

# âœ… æ­£ç¡®åšæ³•  
def extract_image_with_context(paragraph_index, image_index):
    return {
        'paragraph': paragraph_index,
        'order': image_index,
        'data': image_data
        # ä½ç½®å°±æ˜¯æœ€å¥½çš„åˆ†ç±»ï¼
    }
```

### é™·é˜±2ï¼šå¯»æ‰¾å¤æ‚çš„é¢˜ç›®å±‚çº§å…³ç³»
```python
# âŒ é”™è¯¯æ€è·¯
"è¿™æ˜¯å¤§é¢˜è¿˜æ˜¯å°é¢˜ï¼Ÿ"
"è¿™ä¸ªææ–™å±äºå“ªå‡ ä¸ªå°é¢˜ï¼Ÿ"

# âœ… æ­£ç¡®æ€è·¯
"ä»é¢˜ç›®ç¼–å·Xåˆ°é¢˜ç›®ç¼–å·Yï¼Œä¸­é—´çš„å†…å®¹éƒ½å±äºé¢˜ç›®X"
```

### é™·é˜±3ï¼šä½¿ç”¨å¤æ‚çš„AIæ¨¡å‹
```python
# âŒ ä¸éœ€è¦
await openai_api.analyze_document_structure()
local_llm.classify_question_type()

# âœ… ç®€å•è§„åˆ™å°±å¤Ÿäº†
re.match(r'^\d+$', text)  # è¯†åˆ«é¢˜ç›®ç¼–å·
re.match(r'^[ä¸€äºŒä¸‰å››äº”]ã€', text)  # è¯†åˆ«é¢˜å‹
```

---

## ğŸ¯ æˆåŠŸéªŒè¯æ ‡å‡†

å®ç°å®Œæˆåï¼Œä½ çš„ç»“æœåº”è¯¥æ»¡è¶³ï¼š
- âœ… æ€»é¢˜ç›®æ•°ï¼š135é“
- âœ… é¢˜å‹åˆ†å¸ƒï¼š20+15+30+15+55
- âœ… æ¯é“é¢˜éƒ½æœ‰å®Œæ•´å†…å®¹
- âœ… å›¾ç‰‡æ€»æ•°æ¥è¿‘3288å¼ 
- âœ… å¤„ç†æ—¶é—´ï¼š2-5åˆ†é’Ÿ

å¦‚æœæ•°é‡å¯¹ä¸ä¸Šï¼Œè¯´æ˜å®ç°æœ‰é—®é¢˜ï¼

---

## ğŸ“ æœ€åçš„æé†’

**è®°ä½**ï¼šè¿™ä¸ªä»»åŠ¡çœ‹èµ·æ¥å¤æ‚ï¼Œå®é™…ä¸Šå¾ˆç®€å•ã€‚ä¹‹å‰å¤±è´¥æ˜¯å› ä¸ºè¿‡åº¦å¤æ‚åŒ–äº†ã€‚

**äººç±»çš„åšæ³•**ï¼š
1. ğŸ‘ï¸ çœ‹åˆ°é¢˜å‹æ ‡è¯† â†’ å¼€å§‹æ–°section
2. ğŸ”¢ çœ‹åˆ°é¢˜ç›®ç¼–å· â†’ å¼€å§‹æ–°é¢˜ç›®
3. ğŸ“‹ å¤åˆ¶åˆ°ä¸‹ä¸ªç¼–å· â†’ å®Œæˆä¸€é“é¢˜
4. ğŸ”„ é‡å¤...

**ä½ çš„ç¨‹åº**ï¼š
1. æ­£åˆ™åŒ¹é…é¢˜å‹æ ‡è¯†
2. æ­£åˆ™åŒ¹é…é¢˜ç›®ç¼–å·  
3. æŒ‰èŒƒå›´æå–å†…å®¹
4. å¾ªç¯å¤„ç†

å°±è¿™ä¹ˆç®€å•ï¼ä¸è¦æƒ³å¤æ‚äº†ï¼

---

*è¿™ä¸ªè¡¥å……æ–‡æ¡£åŸºäºçœŸå®çš„è¡€æ³ªåˆ†æï¼ŒåŒ…å«äº†æ‰€æœ‰å…³é”®ç»†èŠ‚ã€‚æŒ‰ç…§è¿™ä¸ªåšï¼ŒæˆåŠŸç‡90%+ï¼*








